{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "English {PyPortfolioOpt is a library designed to simplify the process of building and optimizing investment portfolios in Python.}\n",
        "\n",
        "Turkish {PyPortfolioOpt, Python'da yatırım portföylerini oluşturmayı ve optimize etmeyi basitleştirmek üzere tasarlanmış bir kütüphanedir.}"
      ],
      "metadata": {
        "id": "kP5sorG_IaLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPortfolioOpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXqhRWZQwMRE",
        "outputId": "2d4af4eb-01b4-4e6e-ad22-2fe352adc2b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPortfolioOpt in /usr/local/lib/python3.10/dist-packages (1.5.5)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.5.3)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.10.1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (3.2.3)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2022.7.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.1.7.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19->PyPortfolioOpt) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{import pandas as pd: Imports the Pandas library, which is used for data manipulation and analysis, and assigns it the alias pd.\n",
        "import numpy as np: Imports the NumPy library, which is used for numerical computing and working with arrays, and assigns it the alias np.\n",
        "from sklearn.model_selection import train_test_split: Imports the train_test_split function from the scikit-learn library, which is used to split data into training and test sets.\n",
        "from scipy.optimize import minimize: Imports the minimize function from the SciPy library, which is used for mathematical optimization.\n",
        "from pypfopt import risk_models, expected_returns: Imports the risk_models and expected_returns modules from the PyPortfolioOpt library, used for portfolio optimization.\n",
        "import gym: Imports the OpenAI Gym library, which provides environments for developing and comparing reinforcement learning algorithms.\n",
        "from gym import spaces: Imports the spaces module from the Gym library, used to define action and observation spaces.\n",
        "from stable_baselines3 import A2C: Imports the A2C algorithm from the Stable Baselines3 library, used for reinforcement learning.\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv: Imports the DummyVecEnv class from Stable Baselines3, used to wrap environments for reinforcement learning.}\n",
        "\n",
        "###Turkish\n",
        "{import pandas as pd: Veri manipülasyonu ve analizi için kullanılan Pandas kütüphanesini içe aktarır ve pd takma adını atar.\n",
        "import numpy as np: Sayısal hesaplama ve dizilerle çalışmak için kullanılan NumPy kütüphanesini içe aktarır ve np takma adını atar.\n",
        "from sklearn.model_selection import train_test_split: Scikit-learn kütüphanesinden train_test_split fonksiyonunu içe aktarır; bu fonksiyon, verileri eğitim ve test setlerine ayırmak için kullanılır.\n",
        "from scipy.optimize import minimize: Matematiksel optimizasyon için kullanılan SciPy kütüphanesinden minimize fonksiyonunu içe aktarır.\n",
        "from pypfopt import risk_models, expected_returns: Portföy optimizasyonu için kullanılan PyPortfolioOpt kütüphanesinden risk_models ve expected_returns modüllerini içe aktarır.\n",
        "import gym: Güçlendirme öğrenimi algoritmalarını geliştirmek ve karşılaştırmak için ortamlar sağlayan OpenAI Gym kütüphanesini içe aktarır.\n",
        "from gym import spaces: Eylem ve gözlem alanlarını tanımlamak için kullanılan Gym kütüphanesinden spaces modülünü içe aktarır.\n",
        "from stable_baselines3 import A2C: Güçlendirme öğrenimi için kullanılan Stable Baselines3 kütüphanesinden A2C algoritmasını içe aktarır.\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv: Güçlendirme öğrenimi için ortamları sarmak üzere kullanılan Stable Baselines3'ten DummyVecEnv sınıfını içe aktarır.}"
      ],
      "metadata": {
        "id": "018iN6ZWiFgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "from pypfopt import risk_models, expected_returns\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n"
      ],
      "metadata": {
        "id": "M5aEXS5shPO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{portfolio_df = pd.read_csv('/content/Arya Trader - Sample Data - Model.csv'): Reads the CSV file located at the given path into a Pandas DataFrame, portfolio_df.\n",
        "portfolio_df['dateOpened'] = pd.to_datetime(portfolio_df['dateOpened']): Converts the dateOpened column from a string to a datetime object, which allows for easier handling of date and time operations.\n",
        "portfolio_df['dateClosed'] = pd.to_datetime(portfolio_df['dateClosed']): Converts the dateClosed column to a datetime object as well.\n",
        "portfolio_df.head(): Returns and displays the first five rows of the DataFrame, allowing you to quickly inspect the top of the dataset.}\n",
        "\n",
        "###Turkish\n",
        "{portfolio_df = pd.read_csv('/content/Arya Trader - Sample Data - Model.csv'): Belirtilen yolda bulunan CSV dosyasını, portfolio_df adlı Pandas DataFrame'ine okur.\n",
        "portfolio_df['dateOpened'] = pd.to_datetime(portfolio_df['dateOpened']): dateOpened sütununu bir dize (string) olarak bir tarih ve saat nesnesine dönüştürür, böylece tarih ve saat işlemlerini daha kolay bir şekilde gerçekleştirebilirsiniz.\n",
        "portfolio_df['dateClosed'] = pd.to_datetime(portfolio_df['dateClosed']): dateClosed sütununu da bir tarih ve saat nesnesine dönüştürür.\n",
        "portfolio_df.head(): DataFrame'in ilk beş satırını döndürür ve görüntüler, böylece veri kümesinin başını hızlı bir şekilde inceleyebilirsiniz.}"
      ],
      "metadata": {
        "id": "SJ4Br6QuihoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "portfolio_df = pd.read_csv('/content/Arya Trader - Sample Data - Model.csv')\n",
        "portfolio_df['dateOpened'] = pd.to_datetime(portfolio_df['dateOpened'])\n",
        "portfolio_df['dateClosed'] = pd.to_datetime(portfolio_df['dateClosed'])\n",
        "portfolio_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CV7MEp3rlGIj",
        "outputId": "ab1079da-a306-4b4d-b991-79d401466f91"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   roboID              dateOpened              dateClosed  profit\n",
              "0   13837 2022-05-31 18:49:06.023 2022-06-01 11:55:01.530      30\n",
              "1   13837 2022-06-01 12:04:06.070 2022-06-01 14:06:16.120      30\n",
              "2   13837 2022-06-01 22:06:06.130 2022-06-03 00:30:04.450    -100\n",
              "3   13837 2022-06-03 04:54:06.877 2022-06-09 14:18:03.847    -100\n",
              "4   13837 2022-06-10 02:48:08.927 2022-06-10 09:18:13.750      30"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a9715436-496f-48c4-b434-d81329b85eea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>roboID</th>\n",
              "      <th>dateOpened</th>\n",
              "      <th>dateClosed</th>\n",
              "      <th>profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13837</td>\n",
              "      <td>2022-05-31 18:49:06.023</td>\n",
              "      <td>2022-06-01 11:55:01.530</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13837</td>\n",
              "      <td>2022-06-01 12:04:06.070</td>\n",
              "      <td>2022-06-01 14:06:16.120</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13837</td>\n",
              "      <td>2022-06-01 22:06:06.130</td>\n",
              "      <td>2022-06-03 00:30:04.450</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13837</td>\n",
              "      <td>2022-06-03 04:54:06.877</td>\n",
              "      <td>2022-06-09 14:18:03.847</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13837</td>\n",
              "      <td>2022-06-10 02:48:08.927</td>\n",
              "      <td>2022-06-10 09:18:13.750</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9715436-496f-48c4-b434-d81329b85eea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-737ad46d-e6ea-4a98-ac83-9af7f7207aea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-737ad46d-e6ea-4a98-ac83-9af7f7207aea')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-737ad46d-e6ea-4a98-ac83-9af7f7207aea button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9715436-496f-48c4-b434-d81329b85eea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9715436-496f-48c4-b434-d81329b85eea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{num_robots = portfolio_df['roboID'].nunique(): This line calculates the number of unique robot IDs in the roboID column of the DataFrame portfolio_df. The nunique() method returns the count of distinct values.\n",
        "num_time_steps = len(portfolio_df['dateOpened'].unique()): This line calculates the number of unique time steps by finding the unique values in the dateOpened column and then taking the length of that unique array.\n",
        "num_robots, num_time_steps: This line will return and display the values of num_robots and num_time_steps, showing the count of unique robots and unique time steps.}\n",
        "\n",
        "###Turkish\n",
        "{num_robots = portfolio_df['roboID'].nunique(): Bu satır, portfolio_df DataFrame'inin roboID sütunundaki benzersiz robot kimliklerinin sayısını hesaplar. nunique() metodu, farklı değerlerin sayısını döndürür.\n",
        "num_time_steps = len(portfolio_df['dateOpened'].unique()): Bu satır, dateOpened sütunundaki benzersiz değerleri bulup o benzersiz dizinin uzunluğunu alarak benzersiz zaman adımlarının sayısını hesaplar.\n",
        "num_robots, num_time_steps: Bu satır, num_robots ve num_time_steps değerlerini döndürür ve görüntüler, böylece benzersiz robotların ve benzersiz zaman adımlarının sayısını gösterir.}"
      ],
      "metadata": {
        "id": "ThiGonDajDKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_robots = portfolio_df['roboID'].nunique()\n",
        "num_time_steps = len(portfolio_df['dateOpened'].unique())\n",
        "num_robots, num_time_steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWyBR1kalNR3",
        "outputId": "576fe4d5-0146-40a3-8692-dea8619f2bdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 8390)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Pivoting the DataFrame:\n",
        "pivot_df = portfolio_df.pivot(index='dateOpened', columns='roboID', values='profit'): This line pivots the DataFrame so that each row represents a unique date, and each column represents a unique robot ID. The values in the DataFrame are the profit values.\n",
        "\n",
        "Replacing NaN Values:\n",
        "pivot_df.fillna(0, inplace=True): This line replaces any NaN (Not a Number) values in the DataFrame with 0.\n",
        "\n",
        "Splitting the Data:\n",
        "train_df, test_df = train_test_split(pivot_df, test_size=0.2, shuffle=False): This line splits the pivoted DataFrame into a training set (80%) and a test set (20%) without shuffling the data.\n",
        "\n",
        "Reshaping the Data:\n",
        "train_data = train_df.values.reshape((train_df.shape[0], train_df.shape[1], 1))\n",
        "test_data = test_df.values.reshape((test_df.shape[0], test_df.shape[1], 1)): These lines reshape the data into a 3D array, which is a required format for many deep learning models.\n",
        "\n",
        "Returning Shapes:\n",
        "train_data.shape, test_data.shape: This line returns and displays the shapes of the training and test data arrays, allowing you to verify that they have been reshaped correctly.}\n",
        "\n",
        "###Turkish\n",
        "{DataFrame'i Döndürme:\n",
        "pivot_df = portfolio_df.pivot(index='dateOpened', columns='roboID', values='profit'): Bu satır, her satırın benzersiz bir tarihi, her sütunun benzersiz bir robot kimliğini temsil ettiği şekilde DataFrame'i döndürür. DataFrame'deki değerler kar marjı değerleridir.\n",
        "\n",
        "NaN Değerlerini Değiştirme:\n",
        "pivot_df.fillna(0, inplace=True): Bu satır, DataFrame'deki NaN (Sayı Olmayan) değerlerini 0 ile değiştirir.\n",
        "\n",
        "Verileri Bölme:\n",
        "train_df, test_df = train_test_split(pivot_df, test_size=0.2, shuffle=False): Bu satır, döndürülmüş DataFrame'i eğitim kümesi (%80) ve test kümesi (%20) olarak böler ve verileri karıştırmaz.\n",
        "\n",
        "Verileri Yeniden Şekillendirme:\n",
        "train_data = train_df.values.reshape((train_df.shape[0], train_df.shape[1], 1))\n",
        "test_data = test_df.values.reshape((test_df.shape[0], test_df.shape[1], 1)): Bu satırlar, verileri birçok derin öğrenme modeli için gerekli olan bir 3D diziye dönüştürür.\n",
        "\n",
        "Şekilleri Döndürme:\n",
        "train_data.shape, test_data.shape: Bu satır, eğitim ve test verisi dizilerinin şekillerini döndürür ve görüntüler, böylece doğru şekilde yeniden şekillendirildiklerini doğrulamanıza izin verir.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "_tq7fOsejbtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df = portfolio_df.pivot(index='dateOpened', columns='roboID', values='profit')\n",
        "pivot_df.fillna(0, inplace=True)\n",
        "train_df, test_df = train_test_split(pivot_df, test_size=0.2, shuffle=False)\n",
        "train_data = train_df.values.reshape((train_df.shape[0], train_df.shape[1], 1))\n",
        "test_data = test_df.values.reshape((test_df.shape[0], test_df.shape[1], 1))\n",
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwErXv_WlQ9u",
        "outputId": "ea9d10b4-04e7-4fa5-db85-2dfaf3dda388"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6712, 100, 1), (1678, 100, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{we can use Monte Carlo simulations for portfolio optimization. The main idea behind this approach is to generate a large number of random portfolio weights, calculate the portfolio returns and risk for each, and then identify the portfolio weights that yield the best trade-off between risk and return.\n",
        "\n",
        "This method is based on Modern Portfolio Theory, which states that an optimal portfolio can be formed by considering the trade-off between risk and return. In this context, risk is typically measured as the standard deviation of portfolio returns.\n",
        "\n",
        "Here are the steps we'll take:\n",
        "\n",
        "Calculate the historical return and volatility for each robot.\n",
        "Generate a large number of random portfolio weights.\n",
        "Calculate the portfolio return and volatility for each set of weights.\n",
        "Identify the portfolio with the best Sharpe Ratio (return/volatility).}\n",
        "\n",
        "###Turkish\n",
        "{Portföy optimizasyonu için Monte Carlo simülasyonlarını kullanabiliriz. Bu yaklaşımın arkasındaki ana fikir, çok sayıda rastgele portföy ağırlığı oluşturmak, her biri için portföy getirilerini ve riskini hesaplamak ve ardından risk ve getiri arasındaki en iyi dengeyi sağlayan portföy ağırlıklarını belirlemektir.\n",
        "\n",
        "Bu yöntem, Modern Portföy Teorisi'ne dayanmaktadır ve bu teori, risk ve getiri arasındaki dengeyi göz önünde bulundurarak optimal bir portföy oluşturulabileceğini belirtir. Bu bağlamda, risk genellikle portföy getirilerinin standart sapması olarak ölçülür.\n",
        "\n",
        "İşte atacağımız adımlar:\n",
        "\n",
        "Her robot için tarihsel getiri ve volatiliteyi hesaplayın. Büyük sayıda rastgele portföy ağırlığı oluşturun. Her ağırlık seti için portföy getirisini ve volatilitesini hesaplayın. En iyi Sharpe Oranına (getiri/volatilite) sahip portföyü belirleyin.}"
      ],
      "metadata": {
        "id": "Mqrg4hXCm15N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Pivoting the DataFrame:\n",
        "returns = portfolio_df.pivot(index='dateOpened', columns='roboID', values='profit'): This line pivots the DataFrame, so that each row represents a unique date, and each column represents a unique robot ID. The values in the DataFrame are the profit values.\n",
        "\n",
        "Calculating Average Returns:\n",
        "average_returns = returns.mean(): This line calculates the mean of the profit values for each robot, giving the historical average return for each robot.\n",
        "\n",
        "Calculating Volatility:\n",
        "volatility = returns.std(): This line calculates the standard deviation of the profit values for each robot, giving the historical volatility for each robot.\n",
        "\n",
        "Returning Results:\n",
        "average_returns, volatility: This line returns and displays the calculated average returns and volatilities, allowing you to see the values for each robot.}\n",
        "\n",
        "###Turkish\n",
        "{DataFrame'i Döndürme:\n",
        "returns = portfolio_df.pivot(index='dateOpened', columns='roboID', values='profit'): Bu satır, her satırın benzersiz bir tarihi, her sütunun benzersiz bir robot kimliğini temsil ettiği şekilde DataFrame'i döndürür. DataFrame'deki değerler kar marjı değerleridir.\n",
        "\n",
        "Ortalama Getirileri Hesaplama:\n",
        "average_returns = returns.mean(): Bu satır, her robot için kar değerlerinin ortalamasını hesaplar, böylece her robot için tarihsel ortalama getiriyi verir.\n",
        "\n",
        "Volatilite Hesaplama:\n",
        "volatility = returns.std(): Bu satır, her robot için kar değerlerinin standart sapmasını hesaplar, böylece her robot için tarihsel volatiliteyi verir.\n",
        "\n",
        "Sonuçları Döndürme:\n",
        "average_returns, volatility: Bu satır, hesaplanan ortalama getirileri ve volatiliteleri döndürür ve görüntüler, böylece her robot için değerleri görebilirsiniz.}"
      ],
      "metadata": {
        "id": "KcyBtw1fj8fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "returns = portfolio_df.pivot(index='dateOpened', columns='roboID', values='profit')\n",
        "average_returns = returns.mean()\n",
        "volatility = returns.std()\n",
        "average_returns, volatility"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UliqzxzmibE",
        "outputId": "46c7699c-147c-46b8-8578-bbfc5c780b6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(roboID\n",
              " 58        7.142857\n",
              " 74        6.630435\n",
              " 88        5.714286\n",
              " 188       7.564767\n",
              " 256      14.000000\n",
              "            ...    \n",
              " 21310     9.480519\n",
              " 21376     2.588235\n",
              " 21474    19.545455\n",
              " 21475    27.777778\n",
              " 21501    32.592593\n",
              " Length: 100, dtype: float64,\n",
              " roboID\n",
              " 58       102.286363\n",
              " 74        50.454575\n",
              " 88        86.871076\n",
              " 188       36.668237\n",
              " 256       77.617587\n",
              "             ...    \n",
              " 21310     85.376813\n",
              " 21376     45.040865\n",
              " 21474    102.648494\n",
              " 21475     97.427222\n",
              " 21501    142.709835\n",
              " Length: 100, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{We have completed the Monte Carlo simulation for portfolio optimization. The optimal weights for the portfolio are given by the array optimal_weights. These weights provide the highest Sharpe ratio (the ratio of return to volatility) among the 1000 randomly generated portfolios.\n",
        "\n",
        "Here are the details for the optimal portfolio:\n",
        "\n",
        "Weights: optimal_weights\n",
        "Expected return: 16.16\n",
        "Expected volatility: 11.20\n",
        "Sharpe ratio: 1.44\n",
        "This means that if you distribute your investment among the robots according to the optimal_weights, you can expect a return of 16.16 with a volatility of 11.20. This portfolio has the highest Sharpe ratio among the 1000 portfolios we simulated, meaning it provides the best risk-adjusted return.\n",
        "\n",
        "Please note that these results are based on historical data and may not predict future performance. Also, the weights might not sum up exactly to 1 due to numerical precision issues, but they should be very close.\n",
        "\n",
        "Keep in mind that this is a simplified example. In a real-world situation, you might want to take into account transaction costs, adjust for risk using a risk-free rate, or include other constraints in the portfolio optimization process.}\n",
        "\n",
        "###Turkish\n",
        "{Portföy optimizasyonu için Monte Carlo simülasyonunu tamamladık. Portföy için en uygun ağırlıklar, optimal_weights dizisi tarafından verilir. Bu ağırlıklar, 1000 rastgele oluşturulan portföy arasında en yüksek Sharpe oranını (getiri ile volatilite arasındaki oran) sağlar.\n",
        "\n",
        "En uygun portföy için ayrıntılar şunlardır:\n",
        "\n",
        "Ağırlıklar: optimal_weights\n",
        "Beklenen getiri: 16.16\n",
        "Beklenen volatilite: 11.20\n",
        "Sharpe oranı: 1.44\n",
        "Bu, yatırımınızı optimal_weights'e göre robotlar arasında dağıtırsanız, 11.20'lik bir volatilite ile 16.16'lık bir getiri bekleyebileceğiniz anlamına gelir. Bu portföy, simüle ettiğimiz 1000 portföy arasında en yüksek Sharpe oranına sahip olup, en iyi risk düzeltilmiş getiriyi sağlar.\n",
        "\n",
        "Lütfen bu sonuçların tarihsel verilere dayandığını ve gelecekteki performansı öngörmeyebileceğini unutmayın. Ayrıca, ağırlıklar tam olarak 1'e toplamayabilir, ancak sayısal hassasiyet sorunları nedeniyle çok yakın olmalıdır.\n",
        "\n",
        "Bu basit bir örnektir, aklınızda bulundurun. Gerçek dünya durumunda, işlem maliyetlerini dikkate almak, riski risksiz bir oran kullanarak düzeltmek veya portföy optimizasyon sürecinde diğer kısıtlamaları dahil etmek isteyebilirsiniz.}"
      ],
      "metadata": {
        "id": "AlYzFy4Omv8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Setting Number of Portfolios: num_portfolios = 1000: This line sets the number of portfolios to be simulated.\n",
        "\n",
        "Initialize Arrays: These lines initialize arrays to hold portfolio weights, returns, volatility, and Sharpe ratios for all the simulated portfolios.\n",
        "\n",
        "Simulate Portfolios: The for loop simulates the portfolios:\n",
        "\n",
        "Generate Random Weights: Weights are randomly generated and normalized so that they sum to 1.\n",
        "Calculate Portfolio Return and Volatility: Portfolio return and volatility are calculated for each portfolio using the weights and previously calculated average returns and volatility.\n",
        "Calculate Sharpe Ratio: The Sharpe ratio is calculated as the ratio of return to volatility for each portfolio.\n",
        "Find Optimal Portfolio: The index of the portfolio with the highest Sharpe ratio is found, and its weights, return, volatility, and Sharpe ratio are stored in the corresponding variables.}\n",
        "\n",
        "###Turkish\n",
        "{Portföy Sayısını Ayarlama: num_portfolios = 1000: Bu satır, simüle edilecek portföy sayısını belirler.\n",
        "\n",
        "Dizileri Başlatma: Bu satırlar, tüm simüle edilmiş portföyler için portföy ağırlıkları, getiriler, volatilite ve Sharpe oranlarını tutacak dizileri başlatır.\n",
        "\n",
        "Portföyleri Simüle Etme: for döngüsü portföyleri simüle eder:\n",
        "\n",
        "Rastgele Ağırlıklar Oluşturma: Ağırlıklar rastgele oluşturulur ve toplamları 1 olacak şekilde normalize edilir.\n",
        "Portföy Getirisi ve Volatilitesini Hesaplama: Her portföy için portföy getirisi ve volatilite, ağırlıklar ve daha önce hesaplanan ortalama getiriler ve volatilite kullanılarak hesaplanır.\n",
        "Sharpe Oranını Hesaplama: Her portföy için Sharpe oranı, getiri ile volatilite oranı olarak hesaplanır.\n",
        "En İyi Portföyü Bulma: En yüksek Sharpe oranına sahip portföyün indeksi bulunur ve ilgili değişkenlerde ağırlıkları, getirisi, volatilitesi ve Sharpe oranı saklanır.}"
      ],
      "metadata": {
        "id": "9jzz3_1Bl-w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_portfolios = 1000\n",
        "weights_arr = np.zeros((num_portfolios, len(average_returns)))\n",
        "returns_arr = np.zeros(num_portfolios)\n",
        "volatility_arr = np.zeros(num_portfolios)\n",
        "sharpe_ratio_arr = np.zeros(num_portfolios)\n",
        "for i in range(num_portfolios):\n",
        "    weights = np.random.random(len(average_returns))\n",
        "    weights /= np.sum(weights)\n",
        "    returns_arr[i] = np.dot(weights, average_returns)\n",
        "    volatility_arr[i] = np.sqrt(np.dot(weights ** 2, volatility ** 2))\n",
        "    sharpe_ratio_arr[i] = returns_arr[i] / volatility_arr[i]\n",
        "    weights_arr[i, :] = weights\n",
        "max_index = np.argmax(sharpe_ratio_arr)\n",
        "optimal_weights = weights_arr[max_index, :]\n",
        "optimal_weights, returns_arr[max_index], volatility_arr[max_index], sharpe_ratio_arr[max_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBSmKlUAmppo",
        "outputId": "3fdb9dea-7a80-43e3-9c5f-3390c18a6692"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00832568, 0.00301539, 0.01709648, 0.01301742, 0.01715788,\n",
              "        0.00970959, 0.01449866, 0.01197953, 0.01724329, 0.01391919,\n",
              "        0.00475316, 0.00637172, 0.01449454, 0.01090079, 0.01153157,\n",
              "        0.01263193, 0.01097594, 0.01582952, 0.00423065, 0.00694843,\n",
              "        0.00194404, 0.0047712 , 0.00190445, 0.01091491, 0.0141023 ,\n",
              "        0.00788009, 0.00822079, 0.01571599, 0.0170744 , 0.00413576,\n",
              "        0.0078916 , 0.00730091, 0.00902369, 0.00663473, 0.00187016,\n",
              "        0.00832174, 0.01244018, 0.01079512, 0.01036274, 0.00654507,\n",
              "        0.01105204, 0.01745022, 0.01426483, 0.01264492, 0.01738719,\n",
              "        0.01722569, 0.01057326, 0.00849365, 0.0076644 , 0.00536002,\n",
              "        0.01400925, 0.00633561, 0.00987232, 0.01211052, 0.01132065,\n",
              "        0.0144501 , 0.00640642, 0.01720464, 0.01354124, 0.01578502,\n",
              "        0.01538578, 0.01319317, 0.00605351, 0.00886205, 0.00828364,\n",
              "        0.00888613, 0.01457256, 0.01641337, 0.01241299, 0.00761351,\n",
              "        0.00039918, 0.01269933, 0.00924922, 0.00813443, 0.00542621,\n",
              "        0.0045135 , 0.01063716, 0.01713638, 0.00744509, 0.01461718,\n",
              "        0.01200427, 0.00315779, 0.01055331, 0.00584894, 0.00929672,\n",
              "        0.00308536, 0.01129115, 0.014775  , 0.00897529, 0.0140614 ,\n",
              "        0.01184163, 0.01278691, 0.0042533 , 0.00299547, 0.00658144,\n",
              "        0.00115608, 0.00591564, 0.00693378, 0.00715556, 0.00976333]),\n",
              " 14.679635399179553,\n",
              " 9.942768866474468,\n",
              " 1.4764132201319786)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using deeplearning method"
      ],
      "metadata": {
        "id": "lsmvv21SmXYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Loading Data: df = pd.read_csv(...): Loads the CSV file containing the trading data.\n",
        "\n",
        "Converting Dates: Converts the 'dateOpened' and 'dateClosed' columns to datetime objects.\n",
        "\n",
        "Pivoting Data: df.pivot_table(...): Pivots the table so that each robot is represented by a separate column, and the values represent profits.\n",
        "\n",
        "Filling Missing Values: Uses forward-fill to fill missing values and then back-fills any remaining missing values.\n",
        "\n",
        "Calculating Cumulative Profits: df_pivot.cumsum(): Computes the cumulative sum of profits for each robot.\n",
        "\n",
        "Calculating Daily Returns: df_cumulative.pct_change(): Changes the cumulative sum to daily percentage changes (returns).\n",
        "\n",
        "Replacing Infinities: Replaces infinities with NaN.\n",
        "\n",
        "Dropping NaN Values: Drops rows with NaN values.\n",
        "\n",
        "Dropping Zero Variance Columns: Drops columns (robots) that have zero variance, as they do not contribute to the portfolio's risk or return.\n",
        "\n",
        "Calculating Expected Returns and Covariance: Calculates the expected annualized returns and the annualized sample covariance matrix of the asset returns.\n",
        "\n",
        "Ensuring Covariance Matrix is Symmetric: This part makes sure that the covariance matrix is symmetric, filling any NaN values.}\n",
        "\n",
        "###Turkish\n",
        "{Verileri Yükleme: df = pd.read_csv(...): İşlem verilerini içeren CSV dosyasını yükler.\n",
        "\n",
        "Tarihleri Dönüştürme: 'dateOpened' ve 'dateClosed' sütunlarını datetime nesnelerine dönüştürür.\n",
        "\n",
        "Verileri Döndürme: df.pivot_table(...): Her robotu ayrı bir sütunla temsil edecek şekilde tabloyu döndürür ve değerler karları temsil eder.\n",
        "\n",
        "Eksik Değerleri Doldurma: Eksik değerleri doldurmak için ileri doldurma kullanır ve ardından kalan eksik değerleri geri doldurur.\n",
        "\n",
        "Kümülatif Karları Hesaplama: df_pivot.cumsum(): Her robot için kârın kümülatif toplamını hesaplar.\n",
        "\n",
        "Günlük Getirileri Hesaplama: df_cumulative.pct_change(): Kümülatif toplamı günlük yüzde değişimlere (getirilere) dönüştürür.\n",
        "\n",
        "Sonsuzlukları Değiştirme: Sonsuzlukları NaN ile değiştirir.\n",
        "\n",
        "NaN Değerleri Atma: NaN değerleri içeren satırları atar.\n",
        "\n",
        "Sıfır Varyanslı Sütunları Atma: Portföyün riskine veya getirisine katkıda bulunmayan sıfır varyanslı sütunları (robotları) atar.\n",
        "\n",
        "Beklenen Getirileri ve Kovaryansı Hesaplama: Varlık getirilerinin beklenen yıllık getirilerini ve yıllık örnek kovaryans matrisini hesaplar.\n",
        "\n",
        "Kovaryans Matrisinin Simetrik Olmasını Sağlama: Bu bölüm, kovaryans matrisinin simetrik olduğundan emin olur, herhangi bir NaN değerini doldurur.}"
      ],
      "metadata": {
        "id": "9suWa0tvmpjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Arya Trader - Sample Data - Model.csv')\n",
        "\n",
        "df['dateOpened'] = pd.to_datetime(df['dateOpened'])\n",
        "df['dateClosed'] = pd.to_datetime(df['dateClosed'])\n",
        "\n",
        "df_pivot = df.pivot_table(values='profit', index='dateClosed', columns='roboID')\n",
        "\n",
        "df_pivot = df_pivot.fillna(method='ffill')\n",
        "\n",
        "df_pivot = df_pivot.fillna(method='bfill')\n",
        "\n",
        "df_cumulative = df_pivot.cumsum()\n",
        "\n",
        "df_returns = df_cumulative.pct_change()\n",
        "\n",
        "df_returns = df_returns.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "df_returns = df_returns.dropna()\n",
        "\n",
        "df_returns = df_returns.loc[:, df_returns.std() > 0]\n",
        "\n",
        "mu = expected_returns.mean_historical_return(df_returns)\n",
        "S = risk_models.sample_cov(df_returns)\n",
        "\n",
        "S = S.where(np.tril(np.ones(S.shape)).astype(np.bool))\n",
        "S = S.T.fillna(S)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc2MYSxyKzFl",
        "outputId": "c3dc83f9-ae95-4c80-d076-a21bc0fc066f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-210829edda89>:42: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  S = S.where(np.tril(np.ones(S.shape)).astype(np.bool))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{stable-baselines3: This is the name of the package to install. Stable Baselines3 is a set of high-level reinforcement learning models implemented in PyTorch.}\n",
        "\n",
        "###Turkish\n",
        "{stable-baselines3: Yüklenecek paketin adıdır. Stable Baselines3, PyTorch'ta uygulanan yüksek düzeyli pekiştirmeli öğrenme modellerinin bir setidir.}"
      ],
      "metadata": {
        "id": "4l4zuWYKoFNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGbTLx-LXZ5",
        "outputId": "ee580ed0-45a5-490f-ab38-1e4d9a3a77e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.7.0.72)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.12.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.65.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.4.2)\n",
            "Requirement already satisfied: shimmy[atari]~=0.2.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.6.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (8.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.27.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=0.2.1->stable-baselines3[extra]) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3[extra]) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3[extra]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3[extra]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3[extra]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3[extra]) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2022.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=0.2.1->stable-baselines3[extra]) (6.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Englis\n",
        "{gym: This is the name of the package to be installed. The gym library is a toolkit for developing and comparing reinforcement learning algorithms.}\n",
        "\n",
        "###Turkish\n",
        "{gym: Yüklenecek paketin adıdır. gym kütüphanesi, pekiştirmeli öğrenme algoritmalarını geliştirmek ve karşılaştırmak için kullanılan bir araç setidir.}"
      ],
      "metadata": {
        "id": "R0iw2MdcoZQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gquthu9iGDl0",
        "outputId": "e9af1e2f-c728-42c9-808f-6b2f34d6c901"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class TradingEnv(gym.Env): This line defines a new class TradingEnv, which is a subclass of gym.Env. This means that TradingEnv inherits all the properties and methods of gym.Env, but can also have additional properties and methods.\n",
        "\n",
        "def __init__(self, df): This is the initializer method for the class. It takes a dataframe df as input, which contains the price data for the assets to be traded.\n",
        "\n",
        "self.df = df: This line stores the input dataframe in the self.df attribute of the class.\n",
        "\n",
        "self.n_assets = len(df.columns): This line calculates the number of assets in the portfolio, which is the number of columns in the dataframe.\n",
        "\n",
        "self.n_steps = len(df): This line calculates the number of steps in each episode, which is the number of rows in the dataframe.\n",
        "\n",
        "self.current_step = 0: This line initializes the current step to 0.\n",
        "\n",
        "self.action_space = spaces.Box(low=-1, high=1, shape=(self.n_assets,)): This line defines the action space of the environment, which is a continuous space where each action corresponds to the weights assigned to each asset in the portfolio. Each weight can be any real number between -1 and 1.\n",
        "\n",
        "self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_assets,)): This line defines the observation space of the environment, which is also a continuous space where each observation corresponds to the price data for each asset. Each price can be any real number.\n",
        "\n",
        "def step(self, action):: This method takes an action as input and returns the next observation, the reward (portfolio return), and a boolean indicating whether the episode is done.\n",
        "\n",
        "weights = action / np.sum(np.abs(action)): This line normalizes the action vector to get the portfolio weights.\n",
        "\n",
        "portfolio_return = np.dot(weights, current_prices): This line calculates the portfolio return as the dot product of the portfolio weights and the current prices.\n",
        "\n",
        "done = self.current_step == self.n_steps - 1: This line checks whether the episode is done, which is the case when the current step equals the total number of steps.\n",
        "\n",
        "self.current_step += 1: This line increments the current step.\n",
        "\n",
        "def reset(self):: This method resets the environment to its initial state and returns the initial observation.\n",
        "\n",
        "In summary, this code defines a trading environment where an agent can interact with a financial market by allocating weights to different assets to maximize the portfolio return. The state of the environment at each step is the price data for each asset, and the reward is the portfolio return."
      ],
      "metadata": {
        "id": "pgz1DCy_pMih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The TradingEnv class is a custom environment for trading simulations. It's designed to work with RL algorithms that need to interact with an environment to learn optimal trading strategies. Here's a breakdown of the code:\n",
        "\n",
        "Initialization (__init__ method):\n",
        "\n",
        "self.df: The DataFrame containing the asset data.\n",
        "self.n_assets: The number of assets (columns in the DataFrame).\n",
        "self.n_steps: The number of time steps (rows in the DataFrame).\n",
        "self.current_step: The current time step, initialized to 0.\n",
        "self.action_space: Defines the action space as a continuous space where actions represent portfolio weights.\n",
        "self.observation_space: Defines the observation space as a continuous space representing asset prices.\n",
        "Step Method (step method): This method simulates one time step in the environment:\n",
        "\n",
        "Normalizes the action to represent portfolio weights.\n",
        "Calculates the portfolio return based on the current prices.\n",
        "Determines whether the episode is done (reached the last time step).\n",
        "Increments the current step and retrieves the next observation.\n",
        "Returns the next observation, portfolio return, done flag, and an empty info dictionary.\n",
        "Reset Method (reset method): This method resets the environment to its initial state, returning the first observation.}\n",
        "\n",
        "###Turkish\n",
        "{TradingEnv sınıfı, ticaret simülasyonları için özel bir ortamdır. Optimal ticaret stratejilerini öğrenmek için bir ortamla etkileşime girmesi gereken RL algoritmaları ile çalışmak üzere tasarlanmıştır. İşte kodun ayrıntılı açıklaması:\n",
        "\n",
        "Başlangıç (__init__ metodu):\n",
        "\n",
        "self.df: Varlık verilerini içeren DataFrame.\n",
        "self.n_assets: Varlık sayısı (DataFrame'deki sütun sayısı).\n",
        "self.n_steps: Zaman adımı sayısı (DataFrame'deki satır sayısı).\n",
        "self.current_step: Geçerli zaman adımı, 0 olarak başlatılır.\n",
        "self.action_space: Eylem alanını, portföy ağırlıklarını temsil eden sürekli bir alan olarak tanımlar.\n",
        "self.observation_space: Gözlem alanını, varlık fiyatlarını temsil eden sürekli bir alan olarak tanımlar.\n",
        "Adım Metodu (step metodu): Bu metod, ortamda bir zaman adımını simüle eder:\n",
        "\n",
        "Eylemi, portföy ağırlıklarını temsil etmek üzere normalleştirir.\n",
        "Mevcut fiyatlar temelinde portföy getirisini hesaplar.\n",
        "Bölümün bittiğini belirler (son zaman adımına ulaşıldı).\n",
        "Geçerli adımı artırır ve bir sonraki gözlemi alır.\n",
        "Bir sonraki gözlemi, portföy getirisini, bitiş bayrağını ve boş bilgi sözlüğünü döndürür.\n",
        "Sıfırlama Metodu (reset metodu): Bu metod, ortamı başlangıç durumuna sıfırlar ve ilk gözlemi döndürür.}"
      ],
      "metadata": {
        "id": "6Jhj2jHroyDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, df):\n",
        "        super(TradingEnv, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        self.n_assets = len(df.columns)\n",
        "        self.n_steps = len(df)\n",
        "        self.current_step = 0\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.n_assets,))\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_assets,))\n",
        "\n",
        "    def step(self, action):\n",
        "        weights = action / np.sum(np.abs(action))\n",
        "        current_prices = self.df.iloc[self.current_step]\n",
        "        portfolio_return = np.dot(weights, current_prices)\n",
        "\n",
        "        done = self.current_step == self.n_steps - 1\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step < self.n_steps:\n",
        "            next_observation = self.df.iloc[self.current_step]\n",
        "        else:\n",
        "            next_observation = self.df.iloc[-1]\n",
        "\n",
        "        return next_observation, portfolio_return, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        return self.df.iloc[self.current_step]\n"
      ],
      "metadata": {
        "id": "TorETDRwPEAm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is using Stable Baselines3, a library for reinforcement learning in Python that builds on OpenAI's baselines.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "from stable_baselines3 import A2C: This imports the Advantage Actor-Critic (A2C) algorithm. A2C is a type of policy gradient method, which directly optimizes the policy (i.e., the agent's behavior) to maximize expected future rewards.\n",
        "\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv: This imports the DummyVecEnv class, which is used to wrap the trading environment so that it can be used with Stable Baselines3.\n",
        "\n",
        "env = TradingEnv(df_returns): This creates an instance of the trading environment using the returns data.\n",
        "\n",
        "env = DummyVecEnv([lambda: env]): This wraps the environment in a DummyVecEnv, which is necessary for using it with Stable Baselines3. This line of code is essentially a way to convert the environment into a format that Stable Baselines3 can work with.\n",
        "\n",
        "model = A2C('MlpPolicy', env, verbose=1): This creates an instance of the A2C model with a multi-layer perceptron (MLP) policy. The policy defines the way the agent chooses actions. An MLP policy is a neural network policy where the network has one or more hidden layers of neurons between the input and output layers. The verbose=1 argument means that the model will output detailed logs.\n",
        "\n",
        "model.learn(total_timesteps=100000): This trains the model for a total of 100,000 time steps. This line of code is where the actual learning happens.\n",
        "\n",
        "In summary, this code is training a reinforcement learning agent to trade in the custom trading environment using the A2C algorithm. The agent learns a policy for trading that aims to maximize the expected future returns."
      ],
      "metadata": {
        "id": "9oPaLQiqpfv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Create Environment (TradingEnv): The custom trading environment, TradingEnv, is initialized with the DataFrame of returns df_returns.\n",
        "\n",
        "Vectorize Environment (DummyVecEnv): The environment is wrapped in a DummyVecEnv to make it compatible with Stable Baselines3 models. This allows the environment to handle multiple parallel simulations, even though in this case only one environment is used.\n",
        "\n",
        "Create A2C Model: The A2C (Advantage Actor-Critic) model is created using the MlpPolicy, which means that a Multi-Layer Perceptron (MLP) is used as the policy network. The verbose=1 argument enables training logs.\n",
        "\n",
        "Train the Model (model.learn): The model is trained using the learn method with total_timesteps=100000, meaning it will go through 100,000 time steps in the environment during training.}\n",
        "\n",
        "###Turkish\n",
        "{Ortamı Oluştur (TradingEnv): Özel ticaret ortamı TradingEnv, df_returns adlı getiri DataFrame'i ile başlatılır.\n",
        "\n",
        "Ortamı Vektörleştir (DummyVecEnv): Ortam, Stable Baselines3 modelleriyle uyumlu olması için DummyVecEnv içine alınır. Bu, ortamın birden çok paralel simülasyonu işlemesine izin verir, ancak bu durumda yalnızca bir ortam kullanılır.\n",
        "\n",
        "A2C Modelini Oluştur: A2C (Avantaj Aktör-Eleştirmen) modeli, politika ağı olarak Çok Katmanlı Algılayıcı (MLP) kullanıldığı anlamına gelen MlpPolicy ile oluşturulur. verbose=1 argümanı, eğitim günlüklerini etkinleştirir.\n",
        "\n",
        "Modeli Eğit (model.learn): Model, total_timesteps=100000 ile learn metodu kullanılarak\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "IvM7hga1pK8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = TradingEnv(df_returns)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "model = A2C('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=100000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFfrXBfYPH3x",
        "outputId": "8af12403-dd51-4331-d980-d0d71ada2126"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 588      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -388     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 11.4     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.00721  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 556      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -18.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -16.9    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0147   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 618      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.684   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.311   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 9.93e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 657      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -3.78    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -1.59    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000174 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 673      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.401   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.147    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.89e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 685      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.183   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -0.998   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 6.22e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 699      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -1.73    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 7.54     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.003    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 709      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.00535 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.0222   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.32e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 715      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.439    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.103   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.01e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 721      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.711    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.0325   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.99e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 642      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -1.28    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 1.07     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000112 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 604      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.906   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 1.45     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000292 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -3.83    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -1.66    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000166 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 622      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -49.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 6.04     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0032   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 628      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -1.52    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.699    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 3.57e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 625      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.206    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0.0936  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 4.99e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 616      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.305    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.144   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.88e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 621      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.134    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.067    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.41e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 629      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -2.35    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 14.1     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0189   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 618      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.105    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.796    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 4.3e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 596      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.69     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 3.98     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000802 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 583      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.222    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.0283  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 3.16e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 575      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.279   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | -0.357   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 8.83e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 581      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.215    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.132    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.26e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 586      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.301    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -0.142   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.63e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 591      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.208    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 2.65     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000531 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 598      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -3.01    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 1.41     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000114 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 602      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.0075   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | -0.169   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.06e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 606      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -3.7     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.613    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.25e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 606      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.839    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | -0.165   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.15e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 603      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -6.74    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | -7.95    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0118   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 605      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.115    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.192   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.25e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.063   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | -0.249   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 4.06e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -2.6     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 2.36     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000298 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 618      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.463   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -0.0467  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 5.91e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 621      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.803   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 1.29     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0019   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 624      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -30.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 15.4     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0126   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 627      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.526   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -0.402   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.03e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 629      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.178   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 2.49     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.00173  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 621      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -9.53    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 6.23     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.00679  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 624      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 20500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.494    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | -0.174   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.64e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 626      |\n",
            "|    iterations         | 4200     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 21000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.744   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4199     |\n",
            "|    policy_loss        | -0.565   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 4.49e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 628      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.188   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | -0.396   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 9.96e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 631      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.576   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | 0.202    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 5.31e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 633      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.464    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | -1.22    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000168 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 634      |\n",
            "|    iterations         | 4600     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 23000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.791    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4599     |\n",
            "|    policy_loss        | -0.576   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.72e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 632      |\n",
            "|    iterations         | 4700     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 23500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.921   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4699     |\n",
            "|    policy_loss        | -1.33    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000103 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 630      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.551    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | 2.4      |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000547 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 632      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.0325  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | -0.00794 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.75e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 634      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.545    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | -0.644   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 3.43e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 630      |\n",
            "|    iterations         | 5100     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 25500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.448    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5099     |\n",
            "|    policy_loss        | -0.682   |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 2.64e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 624      |\n",
            "|    iterations         | 5200     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -1.94    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5199     |\n",
            "|    policy_loss        | 4.66     |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 0.00111  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 626      |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.908   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | 15.5     |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 0.0125   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 629      |\n",
            "|    iterations         | 5400     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 27000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.157   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5399     |\n",
            "|    policy_loss        | -0.308   |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 5.32e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 631      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.392    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5499     |\n",
            "|    policy_loss        | 0.0464   |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 2.54e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 633      |\n",
            "|    iterations         | 5600     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.182   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5599     |\n",
            "|    policy_loss        | -0.696   |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 2.56e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 635      |\n",
            "|    iterations         | 5700     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 28500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -1.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5699     |\n",
            "|    policy_loss        | -1.97    |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 0.000297 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 637      |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -19.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | -8.19    |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 0.00377  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 639      |\n",
            "|    iterations         | 5900     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 29500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.455   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5899     |\n",
            "|    policy_loss        | 0.000892 |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 1.08e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 640      |\n",
            "|    iterations         | 6000     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 30000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -1.86    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5999     |\n",
            "|    policy_loss        | -0.0327  |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 2.26e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 641      |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 47       |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | -0.0879  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | -0.377   |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 8.57e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 642      |\n",
            "|    iterations         | 6200     |\n",
            "|    time_elapsed       | 48       |\n",
            "|    total_timesteps    | 31000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.203    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6199     |\n",
            "|    policy_loss        | -0.171   |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 2.67e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 641      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 49       |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -142     |\n",
            "|    explained_variance | 0.617    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | 3.08     |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 0.000463 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 639      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.127   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | -0.224   |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 3.67e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 640      |\n",
            "|    iterations         | 6500     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 32500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.181    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6499     |\n",
            "|    policy_loss        | -0.232   |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 2.64e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 642      |\n",
            "|    iterations         | 6600     |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 33000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.491   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6599     |\n",
            "|    policy_loss        | -0.0637  |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 2.68e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 644      |\n",
            "|    iterations         | 6700     |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 33500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -1.44    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6699     |\n",
            "|    policy_loss        | -9.5     |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 0.00445  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 646      |\n",
            "|    iterations         | 6800     |\n",
            "|    time_elapsed       | 52       |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.153    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6799     |\n",
            "|    policy_loss        | -0.0579  |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 1.67e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 647      |\n",
            "|    iterations         | 6900     |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 34500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.148    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6899     |\n",
            "|    policy_loss        | -1.21    |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 8.64e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 649      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -6.36    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | 11.1     |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 0.0194   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 650      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.0849  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | -0.226   |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 3.45e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 651      |\n",
            "|    iterations         | 7200     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.0221   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7199     |\n",
            "|    policy_loss        | -0.216   |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 3.92e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 653      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.465   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | 4.76     |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.00249  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 654      |\n",
            "|    iterations         | 7400     |\n",
            "|    time_elapsed       | 56       |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.211    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7399     |\n",
            "|    policy_loss        | -0.818   |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 3.8e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 655      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.048   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 0.785    |\n",
            "|    std                | 0.991    |\n",
            "|    value_loss         | 3.75e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 656      |\n",
            "|    iterations         | 7600     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -10.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7599     |\n",
            "|    policy_loss        | 2.41     |\n",
            "|    std                | 0.991    |\n",
            "|    value_loss         | 0.0079   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 657      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 58       |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.151   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | 0.00733  |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 8.05e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 659      |\n",
            "|    iterations         | 7800     |\n",
            "|    time_elapsed       | 59       |\n",
            "|    total_timesteps    | 39000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | -0.616   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7799     |\n",
            "|    policy_loss        | 1.17     |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 7.53e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 660      |\n",
            "|    iterations         | 7900     |\n",
            "|    time_elapsed       | 59       |\n",
            "|    total_timesteps    | 39500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.0487   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7899     |\n",
            "|    policy_loss        | -0.454   |\n",
            "|    std                | 0.989    |\n",
            "|    value_loss         | 1.23e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 660      |\n",
            "|    iterations         | 8000     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.296    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7999     |\n",
            "|    policy_loss        | -0.145   |\n",
            "|    std                | 0.989    |\n",
            "|    value_loss         | 1.79e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 658      |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 61       |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.0176   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | -1.25    |\n",
            "|    std                | 0.988    |\n",
            "|    value_loss         | 8.13e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 657      |\n",
            "|    iterations         | 8200     |\n",
            "|    time_elapsed       | 62       |\n",
            "|    total_timesteps    | 41000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -141     |\n",
            "|    explained_variance | 0.0654   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8199     |\n",
            "|    policy_loss        | -0.133   |\n",
            "|    std                | 0.988    |\n",
            "|    value_loss         | 1.08e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 658      |\n",
            "|    iterations         | 8300     |\n",
            "|    time_elapsed       | 63       |\n",
            "|    total_timesteps    | 41500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -1.45    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8299     |\n",
            "|    policy_loss        | 7.15     |\n",
            "|    std                | 0.987    |\n",
            "|    value_loss         | 0.00338  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 659      |\n",
            "|    iterations         | 8400     |\n",
            "|    time_elapsed       | 63       |\n",
            "|    total_timesteps    | 42000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -115     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8399     |\n",
            "|    policy_loss        | 5.07     |\n",
            "|    std                | 0.987    |\n",
            "|    value_loss         | 0.00692  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 660      |\n",
            "|    iterations         | 8500     |\n",
            "|    time_elapsed       | 64       |\n",
            "|    total_timesteps    | 42500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.101    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8499     |\n",
            "|    policy_loss        | 0.121    |\n",
            "|    std                | 0.987    |\n",
            "|    value_loss         | 1.54e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 64       |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.651    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | -0.22    |\n",
            "|    std                | 0.987    |\n",
            "|    value_loss         | 6.61e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 662      |\n",
            "|    iterations         | 8700     |\n",
            "|    time_elapsed       | 65       |\n",
            "|    total_timesteps    | 43500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -0.0521  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8699     |\n",
            "|    policy_loss        | -0.875   |\n",
            "|    std                | 0.986    |\n",
            "|    value_loss         | 4.81e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 8800     |\n",
            "|    time_elapsed       | 66       |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -0.14    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8799     |\n",
            "|    policy_loss        | -1.98    |\n",
            "|    std                | 0.985    |\n",
            "|    value_loss         | 0.000213 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 66       |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.0166   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | -0.932   |\n",
            "|    std                | 0.985    |\n",
            "|    value_loss         | 6.01e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 665      |\n",
            "|    iterations         | 9000     |\n",
            "|    time_elapsed       | 67       |\n",
            "|    total_timesteps    | 45000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.461    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8999     |\n",
            "|    policy_loss        | 0.792    |\n",
            "|    std                | 0.986    |\n",
            "|    value_loss         | 4.06e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 666      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.151    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -0.546   |\n",
            "|    std                | 0.985    |\n",
            "|    value_loss         | 1.73e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -0.172   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | 0.187    |\n",
            "|    std                | 0.985    |\n",
            "|    value_loss         | 2.98e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 9300     |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 46500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.00487  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9299     |\n",
            "|    policy_loss        | -0.179   |\n",
            "|    std                | 0.984    |\n",
            "|    value_loss         | 7.6e-06  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 9400     |\n",
            "|    time_elapsed       | 70       |\n",
            "|    total_timesteps    | 47000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -0.142   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9399     |\n",
            "|    policy_loss        | -0.984   |\n",
            "|    std                | 0.983    |\n",
            "|    value_loss         | 6.24e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 70       |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.0995   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | -0.466   |\n",
            "|    std                | 0.984    |\n",
            "|    value_loss         | 1.32e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 670      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 71       |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -0.26    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | -0.0933  |\n",
            "|    std                | 0.983    |\n",
            "|    value_loss         | 9.64e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 670      |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 72       |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.245    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | -0.372   |\n",
            "|    std                | 0.982    |\n",
            "|    value_loss         | 7.74e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 9800     |\n",
            "|    time_elapsed       | 73       |\n",
            "|    total_timesteps    | 49000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -0.00613 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9799     |\n",
            "|    policy_loss        | -0.356   |\n",
            "|    std                | 0.981    |\n",
            "|    value_loss         | 7.98e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 666      |\n",
            "|    iterations         | 9900     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 49500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.148    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9899     |\n",
            "|    policy_loss        | 0.38     |\n",
            "|    std                | 0.981    |\n",
            "|    value_loss         | 1.04e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 10000    |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.0814   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9999     |\n",
            "|    policy_loss        | -0.302   |\n",
            "|    std                | 0.98     |\n",
            "|    value_loss         | 7.28e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 10100    |\n",
            "|    time_elapsed       | 75       |\n",
            "|    total_timesteps    | 50500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.0379   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10099    |\n",
            "|    policy_loss        | -0.28    |\n",
            "|    std                | 0.98     |\n",
            "|    value_loss         | 5.22e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 10200    |\n",
            "|    time_elapsed       | 76       |\n",
            "|    total_timesteps    | 51000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | -1.42    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10199    |\n",
            "|    policy_loss        | 5.9      |\n",
            "|    std                | 0.979    |\n",
            "|    value_loss         | 0.00405  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 10300    |\n",
            "|    time_elapsed       | 76       |\n",
            "|    total_timesteps    | 51500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -140     |\n",
            "|    explained_variance | 0.346    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10299    |\n",
            "|    policy_loss        | -0.154   |\n",
            "|    std                | 0.979    |\n",
            "|    value_loss         | 1.75e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 10400    |\n",
            "|    time_elapsed       | 77       |\n",
            "|    total_timesteps    | 52000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | 0.0051   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10399    |\n",
            "|    policy_loss        | -0.693   |\n",
            "|    std                | 0.978    |\n",
            "|    value_loss         | 3.05e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 670      |\n",
            "|    iterations         | 10500    |\n",
            "|    time_elapsed       | 78       |\n",
            "|    total_timesteps    | 52500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | 0.12     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10499    |\n",
            "|    policy_loss        | -0.48    |\n",
            "|    std                | 0.977    |\n",
            "|    value_loss         | 1.65e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 671      |\n",
            "|    iterations         | 10600    |\n",
            "|    time_elapsed       | 78       |\n",
            "|    total_timesteps    | 53000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -1.27    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10599    |\n",
            "|    policy_loss        | 0.567    |\n",
            "|    std                | 0.977    |\n",
            "|    value_loss         | 3.97e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 671      |\n",
            "|    iterations         | 10700    |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 53500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -1.57    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10699    |\n",
            "|    policy_loss        | 6.21     |\n",
            "|    std                | 0.977    |\n",
            "|    value_loss         | 0.00213  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 672      |\n",
            "|    iterations         | 10800    |\n",
            "|    time_elapsed       | 80       |\n",
            "|    total_timesteps    | 54000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.707   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10799    |\n",
            "|    policy_loss        | 4.52     |\n",
            "|    std                | 0.976    |\n",
            "|    value_loss         | 0.00109  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 672      |\n",
            "|    iterations         | 10900    |\n",
            "|    time_elapsed       | 80       |\n",
            "|    total_timesteps    | 54500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.0363  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10899    |\n",
            "|    policy_loss        | -0.868   |\n",
            "|    std                | 0.976    |\n",
            "|    value_loss         | 4.09e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 673      |\n",
            "|    iterations         | 11000    |\n",
            "|    time_elapsed       | 81       |\n",
            "|    total_timesteps    | 55000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.0146  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10999    |\n",
            "|    policy_loss        | 0.19     |\n",
            "|    std                | 0.976    |\n",
            "|    value_loss         | 2.11e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 674      |\n",
            "|    iterations         | 11100    |\n",
            "|    time_elapsed       | 82       |\n",
            "|    total_timesteps    | 55500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | 0.0286   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11099    |\n",
            "|    policy_loss        | -0.749   |\n",
            "|    std                | 0.975    |\n",
            "|    value_loss         | 4.15e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 675      |\n",
            "|    iterations         | 11200    |\n",
            "|    time_elapsed       | 82       |\n",
            "|    total_timesteps    | 56000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | 0.347    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11199    |\n",
            "|    policy_loss        | -0.233   |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 2.86e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 675      |\n",
            "|    iterations         | 11300    |\n",
            "|    time_elapsed       | 83       |\n",
            "|    total_timesteps    | 56500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.0186  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11299    |\n",
            "|    policy_loss        | -0.404   |\n",
            "|    std                | 0.973    |\n",
            "|    value_loss         | 8.81e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 675      |\n",
            "|    iterations         | 11400    |\n",
            "|    time_elapsed       | 84       |\n",
            "|    total_timesteps    | 57000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | 0.458    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11399    |\n",
            "|    policy_loss        | 3.69     |\n",
            "|    std                | 0.972    |\n",
            "|    value_loss         | 0.000775 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 674      |\n",
            "|    iterations         | 11500    |\n",
            "|    time_elapsed       | 85       |\n",
            "|    total_timesteps    | 57500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.132   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11499    |\n",
            "|    policy_loss        | -0.082   |\n",
            "|    std                | 0.972    |\n",
            "|    value_loss         | 5.5e-07  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 673      |\n",
            "|    iterations         | 11600    |\n",
            "|    time_elapsed       | 86       |\n",
            "|    total_timesteps    | 58000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -3.9     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11599    |\n",
            "|    policy_loss        | 3.4      |\n",
            "|    std                | 0.971    |\n",
            "|    value_loss         | 0.00254  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 673      |\n",
            "|    iterations         | 11700    |\n",
            "|    time_elapsed       | 86       |\n",
            "|    total_timesteps    | 58500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | 0.0846   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11699    |\n",
            "|    policy_loss        | 0.849    |\n",
            "|    std                | 0.971    |\n",
            "|    value_loss         | 0.000112 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 674      |\n",
            "|    iterations         | 11800    |\n",
            "|    time_elapsed       | 87       |\n",
            "|    total_timesteps    | 59000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.0356  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11799    |\n",
            "|    policy_loss        | -0.319   |\n",
            "|    std                | 0.97     |\n",
            "|    value_loss         | 6.31e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 674      |\n",
            "|    iterations         | 11900    |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 59500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -139     |\n",
            "|    explained_variance | -0.619   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11899    |\n",
            "|    policy_loss        | 11.5     |\n",
            "|    std                | 0.97     |\n",
            "|    value_loss         | 0.0181   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 675      |\n",
            "|    iterations         | 12000    |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 60000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.386    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11999    |\n",
            "|    policy_loss        | -0.742   |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 3.29e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 676      |\n",
            "|    iterations         | 12100    |\n",
            "|    time_elapsed       | 89       |\n",
            "|    total_timesteps    | 60500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.123    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12099    |\n",
            "|    policy_loss        | 8.31     |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 0.00523  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 676      |\n",
            "|    iterations         | 12200    |\n",
            "|    time_elapsed       | 90       |\n",
            "|    total_timesteps    | 61000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.0477   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12199    |\n",
            "|    policy_loss        | -0.93    |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 5.49e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 677      |\n",
            "|    iterations         | 12300    |\n",
            "|    time_elapsed       | 90       |\n",
            "|    total_timesteps    | 61500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -3.25    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12299    |\n",
            "|    policy_loss        | 10.1     |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 0.00566  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 677      |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.165    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | -0.693   |\n",
            "|    std                | 0.969    |\n",
            "|    value_loss         | 3.33e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 678      |\n",
            "|    iterations         | 12500    |\n",
            "|    time_elapsed       | 92       |\n",
            "|    total_timesteps    | 62500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.269    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12499    |\n",
            "|    policy_loss        | -0.182   |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 2.13e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 12600    |\n",
            "|    time_elapsed       | 92       |\n",
            "|    total_timesteps    | 63000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.75     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12599    |\n",
            "|    policy_loss        | -0.644   |\n",
            "|    std                | 0.967    |\n",
            "|    value_loss         | 2.36e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 12700    |\n",
            "|    time_elapsed       | 93       |\n",
            "|    total_timesteps    | 63500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.202    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12699    |\n",
            "|    policy_loss        | 1.85     |\n",
            "|    std                | 0.966    |\n",
            "|    value_loss         | 0.00047  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 680      |\n",
            "|    iterations         | 12800    |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 64000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.0445   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12799    |\n",
            "|    policy_loss        | -0.802   |\n",
            "|    std                | 0.967    |\n",
            "|    value_loss         | 4.02e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 678      |\n",
            "|    iterations         | 12900    |\n",
            "|    time_elapsed       | 95       |\n",
            "|    total_timesteps    | 64500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -0.393   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12899    |\n",
            "|    policy_loss        | 0.106    |\n",
            "|    std                | 0.967    |\n",
            "|    value_loss         | 6.94e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 13000    |\n",
            "|    time_elapsed       | 95       |\n",
            "|    total_timesteps    | 65000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -1.51    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12999    |\n",
            "|    policy_loss        | 0.992    |\n",
            "|    std                | 0.966    |\n",
            "|    value_loss         | 0.000151 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 13100    |\n",
            "|    time_elapsed       | 96       |\n",
            "|    total_timesteps    | 65500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -0.0465  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13099    |\n",
            "|    policy_loss        | -0.551   |\n",
            "|    std                | 0.966    |\n",
            "|    value_loss         | 1.97e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 13200    |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 66000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.401    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13199    |\n",
            "|    policy_loss        | -12.5    |\n",
            "|    std                | 0.966    |\n",
            "|    value_loss         | 0.00873  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 677      |\n",
            "|    iterations         | 13300    |\n",
            "|    time_elapsed       | 98       |\n",
            "|    total_timesteps    | 66500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -0.014   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13299    |\n",
            "|    policy_loss        | -0.967   |\n",
            "|    std                | 0.966    |\n",
            "|    value_loss         | 5.74e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 678      |\n",
            "|    iterations         | 13400    |\n",
            "|    time_elapsed       | 98       |\n",
            "|    total_timesteps    | 67000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.304    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13399    |\n",
            "|    policy_loss        | 0.652    |\n",
            "|    std                | 0.965    |\n",
            "|    value_loss         | 0.00021  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 678      |\n",
            "|    iterations         | 13500    |\n",
            "|    time_elapsed       | 99       |\n",
            "|    total_timesteps    | 67500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -54.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13499    |\n",
            "|    policy_loss        | 0.358    |\n",
            "|    std                | 0.964    |\n",
            "|    value_loss         | 0.00329  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 13600    |\n",
            "|    time_elapsed       | 100      |\n",
            "|    total_timesteps    | 68000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -0.214   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13599    |\n",
            "|    policy_loss        | -1.11    |\n",
            "|    std                | 0.963    |\n",
            "|    value_loss         | 7.02e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 679      |\n",
            "|    iterations         | 13700    |\n",
            "|    time_elapsed       | 100      |\n",
            "|    total_timesteps    | 68500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.31     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13699    |\n",
            "|    policy_loss        | -0.412   |\n",
            "|    std                | 0.963    |\n",
            "|    value_loss         | 1.15e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 680      |\n",
            "|    iterations         | 13800    |\n",
            "|    time_elapsed       | 101      |\n",
            "|    total_timesteps    | 69000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -0.117   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13799    |\n",
            "|    policy_loss        | -1.06    |\n",
            "|    std                | 0.961    |\n",
            "|    value_loss         | 6.36e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 681      |\n",
            "|    iterations         | 13900    |\n",
            "|    time_elapsed       | 102      |\n",
            "|    total_timesteps    | 69500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | -4.33    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13899    |\n",
            "|    policy_loss        | 1.56     |\n",
            "|    std                | 0.96     |\n",
            "|    value_loss         | 0.000141 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 682      |\n",
            "|    iterations         | 14000    |\n",
            "|    time_elapsed       | 102      |\n",
            "|    total_timesteps    | 70000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -138     |\n",
            "|    explained_variance | 0.353    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13999    |\n",
            "|    policy_loss        | -0.841   |\n",
            "|    std                | 0.96     |\n",
            "|    value_loss         | 4.3e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 682      |\n",
            "|    iterations         | 14100    |\n",
            "|    time_elapsed       | 103      |\n",
            "|    total_timesteps    | 70500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.599    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14099    |\n",
            "|    policy_loss        | -0.503   |\n",
            "|    std                | 0.959    |\n",
            "|    value_loss         | 1.57e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 683      |\n",
            "|    iterations         | 14200    |\n",
            "|    time_elapsed       | 103      |\n",
            "|    total_timesteps    | 71000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -0.0473  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14199    |\n",
            "|    policy_loss        | -0.705   |\n",
            "|    std                | 0.958    |\n",
            "|    value_loss         | 3.19e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 683      |\n",
            "|    iterations         | 14300    |\n",
            "|    time_elapsed       | 104      |\n",
            "|    total_timesteps    | 71500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -31.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14299    |\n",
            "|    policy_loss        | 10.9     |\n",
            "|    std                | 0.959    |\n",
            "|    value_loss         | 0.00697  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 684      |\n",
            "|    iterations         | 14400    |\n",
            "|    time_elapsed       | 105      |\n",
            "|    total_timesteps    | 72000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.0607   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14399    |\n",
            "|    policy_loss        | -1.13    |\n",
            "|    std                | 0.958    |\n",
            "|    value_loss         | 8e-05    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 684      |\n",
            "|    iterations         | 14500    |\n",
            "|    time_elapsed       | 105      |\n",
            "|    total_timesteps    | 72500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.145    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14499    |\n",
            "|    policy_loss        | -0.204   |\n",
            "|    std                | 0.958    |\n",
            "|    value_loss         | 2.81e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 685      |\n",
            "|    iterations         | 14600    |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 73000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -1.96    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14599    |\n",
            "|    policy_loss        | -1.27    |\n",
            "|    std                | 0.957    |\n",
            "|    value_loss         | 0.00307  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 14700    |\n",
            "|    time_elapsed       | 107      |\n",
            "|    total_timesteps    | 73500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.233    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14699    |\n",
            "|    policy_loss        | 0.225    |\n",
            "|    std                | 0.958    |\n",
            "|    value_loss         | 4.18e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 14800    |\n",
            "|    time_elapsed       | 107      |\n",
            "|    total_timesteps    | 74000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -0.00599 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14799    |\n",
            "|    policy_loss        | -0.332   |\n",
            "|    std                | 0.958    |\n",
            "|    value_loss         | 7.17e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 14900    |\n",
            "|    time_elapsed       | 108      |\n",
            "|    total_timesteps    | 74500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -0.0366  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14899    |\n",
            "|    policy_loss        | 0.552    |\n",
            "|    std                | 0.955    |\n",
            "|    value_loss         | 2.83e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 15000    |\n",
            "|    time_elapsed       | 109      |\n",
            "|    total_timesteps    | 75000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.186    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14999    |\n",
            "|    policy_loss        | -0.00368 |\n",
            "|    std                | 0.955    |\n",
            "|    value_loss         | 4.04e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 684      |\n",
            "|    iterations         | 15100    |\n",
            "|    time_elapsed       | 110      |\n",
            "|    total_timesteps    | 75500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -61.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15099    |\n",
            "|    policy_loss        | -0.995   |\n",
            "|    std                | 0.955    |\n",
            "|    value_loss         | 7.82e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 685      |\n",
            "|    iterations         | 15200    |\n",
            "|    time_elapsed       | 110      |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.17     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15199    |\n",
            "|    policy_loss        | 3.21     |\n",
            "|    std                | 0.955    |\n",
            "|    value_loss         | 0.000695 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 685      |\n",
            "|    iterations         | 15300    |\n",
            "|    time_elapsed       | 111      |\n",
            "|    total_timesteps    | 76500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.0309   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15299    |\n",
            "|    policy_loss        | -0.599   |\n",
            "|    std                | 0.955    |\n",
            "|    value_loss         | 2.27e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 15400    |\n",
            "|    time_elapsed       | 112      |\n",
            "|    total_timesteps    | 77000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | -0.159   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15399    |\n",
            "|    policy_loss        | 5.12     |\n",
            "|    std                | 0.953    |\n",
            "|    value_loss         | 0.00157  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 15500    |\n",
            "|    time_elapsed       | 112      |\n",
            "|    total_timesteps    | 77500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.241    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15499    |\n",
            "|    policy_loss        | -1.37    |\n",
            "|    std                | 0.952    |\n",
            "|    value_loss         | 0.000115 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 687      |\n",
            "|    iterations         | 15600    |\n",
            "|    time_elapsed       | 113      |\n",
            "|    total_timesteps    | 78000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.079    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15599    |\n",
            "|    policy_loss        | -0.642   |\n",
            "|    std                | 0.951    |\n",
            "|    value_loss         | 2.96e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 687      |\n",
            "|    iterations         | 15700    |\n",
            "|    time_elapsed       | 114      |\n",
            "|    total_timesteps    | 78500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -137     |\n",
            "|    explained_variance | 0.0707   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15699    |\n",
            "|    policy_loss        | -0.65    |\n",
            "|    std                | 0.951    |\n",
            "|    value_loss         | 3.01e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 688      |\n",
            "|    iterations         | 15800    |\n",
            "|    time_elapsed       | 114      |\n",
            "|    total_timesteps    | 79000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.248    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15799    |\n",
            "|    policy_loss        | 0.891    |\n",
            "|    std                | 0.95     |\n",
            "|    value_loss         | 4.61e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 688      |\n",
            "|    iterations         | 15900    |\n",
            "|    time_elapsed       | 115      |\n",
            "|    total_timesteps    | 79500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.386    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15899    |\n",
            "|    policy_loss        | 0.158    |\n",
            "|    std                | 0.95     |\n",
            "|    value_loss         | 1.65e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 689      |\n",
            "|    iterations         | 16000    |\n",
            "|    time_elapsed       | 116      |\n",
            "|    total_timesteps    | 80000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.373    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15999    |\n",
            "|    policy_loss        | 2.4      |\n",
            "|    std                | 0.949    |\n",
            "|    value_loss         | 0.000455 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 689      |\n",
            "|    iterations         | 16100    |\n",
            "|    time_elapsed       | 116      |\n",
            "|    total_timesteps    | 80500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.167    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16099    |\n",
            "|    policy_loss        | -0.965   |\n",
            "|    std                | 0.949    |\n",
            "|    value_loss         | 5.5e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 690      |\n",
            "|    iterations         | 16200    |\n",
            "|    time_elapsed       | 117      |\n",
            "|    total_timesteps    | 81000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.174    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16199    |\n",
            "|    policy_loss        | -0.236   |\n",
            "|    std                | 0.949    |\n",
            "|    value_loss         | 3.69e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 690      |\n",
            "|    iterations         | 16300    |\n",
            "|    time_elapsed       | 117      |\n",
            "|    total_timesteps    | 81500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -0.376   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16299    |\n",
            "|    policy_loss        | -0.309   |\n",
            "|    std                | 0.948    |\n",
            "|    value_loss         | 8.63e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 16400    |\n",
            "|    time_elapsed       | 118      |\n",
            "|    total_timesteps    | 82000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.0262   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16399    |\n",
            "|    policy_loss        | -0.559   |\n",
            "|    std                | 0.949    |\n",
            "|    value_loss         | 2.08e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 16500    |\n",
            "|    time_elapsed       | 119      |\n",
            "|    total_timesteps    | 82500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -1.18    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16499    |\n",
            "|    policy_loss        | 0.686    |\n",
            "|    std                | 0.95     |\n",
            "|    value_loss         | 2.9e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 16600    |\n",
            "|    time_elapsed       | 119      |\n",
            "|    total_timesteps    | 83000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.296    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16599    |\n",
            "|    policy_loss        | -2.01    |\n",
            "|    std                | 0.95     |\n",
            "|    value_loss         | 0.000253 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 16700    |\n",
            "|    time_elapsed       | 120      |\n",
            "|    total_timesteps    | 83500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -0.771   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16699    |\n",
            "|    policy_loss        | -0.562   |\n",
            "|    std                | 0.948    |\n",
            "|    value_loss         | 1.74e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 690      |\n",
            "|    iterations         | 16800    |\n",
            "|    time_elapsed       | 121      |\n",
            "|    total_timesteps    | 84000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -0.479   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16799    |\n",
            "|    policy_loss        | -1.01    |\n",
            "|    std                | 0.947    |\n",
            "|    value_loss         | 6.09e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 689      |\n",
            "|    iterations         | 16900    |\n",
            "|    time_elapsed       | 122      |\n",
            "|    total_timesteps    | 84500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -0.0217  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16899    |\n",
            "|    policy_loss        | -1.3     |\n",
            "|    std                | 0.946    |\n",
            "|    value_loss         | 0.000101 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 689      |\n",
            "|    iterations         | 17000    |\n",
            "|    time_elapsed       | 123      |\n",
            "|    total_timesteps    | 85000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -0.676   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16999    |\n",
            "|    policy_loss        | -0.269   |\n",
            "|    std                | 0.946    |\n",
            "|    value_loss         | 3.91e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 690      |\n",
            "|    iterations         | 17100    |\n",
            "|    time_elapsed       | 123      |\n",
            "|    total_timesteps    | 85500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.796    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17099    |\n",
            "|    policy_loss        | 1.41     |\n",
            "|    std                | 0.946    |\n",
            "|    value_loss         | 0.000413 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 17200    |\n",
            "|    time_elapsed       | 124      |\n",
            "|    total_timesteps    | 86000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.727    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17199    |\n",
            "|    policy_loss        | -0.348   |\n",
            "|    std                | 0.945    |\n",
            "|    value_loss         | 8.29e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 17300    |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 86500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.67     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17299    |\n",
            "|    policy_loss        | -0.477   |\n",
            "|    std                | 0.944    |\n",
            "|    value_loss         | 2.52e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 17400    |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 87000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -1.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17399    |\n",
            "|    policy_loss        | -3.04    |\n",
            "|    std                | 0.944    |\n",
            "|    value_loss         | 0.000748 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 17500    |\n",
            "|    time_elapsed       | 126      |\n",
            "|    total_timesteps    | 87500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.44     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17499    |\n",
            "|    policy_loss        | 4.37     |\n",
            "|    std                | 0.944    |\n",
            "|    value_loss         | 0.000923 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 17600    |\n",
            "|    time_elapsed       | 127      |\n",
            "|    total_timesteps    | 88000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.304    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17599    |\n",
            "|    policy_loss        | -1.06    |\n",
            "|    std                | 0.944    |\n",
            "|    value_loss         | 6.72e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 17700    |\n",
            "|    time_elapsed       | 127      |\n",
            "|    total_timesteps    | 88500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | 0.279    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17699    |\n",
            "|    policy_loss        | -1.13    |\n",
            "|    std                | 0.943    |\n",
            "|    value_loss         | 8.3e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 17800    |\n",
            "|    time_elapsed       | 128      |\n",
            "|    total_timesteps    | 89000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -136     |\n",
            "|    explained_variance | -2.07    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17799    |\n",
            "|    policy_loss        | 0.00511  |\n",
            "|    std                | 0.942    |\n",
            "|    value_loss         | 8.79e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 17900    |\n",
            "|    time_elapsed       | 128      |\n",
            "|    total_timesteps    | 89500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -0.752   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17899    |\n",
            "|    policy_loss        | 0.364    |\n",
            "|    std                | 0.941    |\n",
            "|    value_loss         | 8.62e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 18000    |\n",
            "|    time_elapsed       | 129      |\n",
            "|    total_timesteps    | 90000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -0.0894  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17999    |\n",
            "|    policy_loss        | 0.725    |\n",
            "|    std                | 0.941    |\n",
            "|    value_loss         | 5.27e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 18100    |\n",
            "|    time_elapsed       | 130      |\n",
            "|    total_timesteps    | 90500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.0437   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18099    |\n",
            "|    policy_loss        | -0.203   |\n",
            "|    std                | 0.941    |\n",
            "|    value_loss         | 3.23e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 18200    |\n",
            "|    time_elapsed       | 130      |\n",
            "|    total_timesteps    | 91000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -24.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18199    |\n",
            "|    policy_loss        | 11.1     |\n",
            "|    std                | 0.94     |\n",
            "|    value_loss         | 0.00764  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 18300    |\n",
            "|    time_elapsed       | 131      |\n",
            "|    total_timesteps    | 91500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -5.25    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18299    |\n",
            "|    policy_loss        | 10.2     |\n",
            "|    std                | 0.938    |\n",
            "|    value_loss         | 0.0104   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 18400    |\n",
            "|    time_elapsed       | 132      |\n",
            "|    total_timesteps    | 92000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.182    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18399    |\n",
            "|    policy_loss        | -0.372   |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 8.99e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 18500    |\n",
            "|    time_elapsed       | 132      |\n",
            "|    total_timesteps    | 92500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.213    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18499    |\n",
            "|    policy_loss        | -0.303   |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 2.37e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 18600    |\n",
            "|    time_elapsed       | 133      |\n",
            "|    total_timesteps    | 93000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -1.14    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18599    |\n",
            "|    policy_loss        | -0.958   |\n",
            "|    std                | 0.936    |\n",
            "|    value_loss         | 6.19e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 18700    |\n",
            "|    time_elapsed       | 134      |\n",
            "|    total_timesteps    | 93500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -7.08    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18699    |\n",
            "|    policy_loss        | 0.414    |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 1.71e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 18800    |\n",
            "|    time_elapsed       | 135      |\n",
            "|    total_timesteps    | 94000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -5.92    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18799    |\n",
            "|    policy_loss        | 4.18     |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 0.000997 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 18900    |\n",
            "|    time_elapsed       | 136      |\n",
            "|    total_timesteps    | 94500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.334    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18899    |\n",
            "|    policy_loss        | -0.603   |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 2.44e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 19000    |\n",
            "|    time_elapsed       | 136      |\n",
            "|    total_timesteps    | 95000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.0805   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18999    |\n",
            "|    policy_loss        | -1.07    |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 7.5e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 19100    |\n",
            "|    time_elapsed       | 137      |\n",
            "|    total_timesteps    | 95500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | -0.773   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19099    |\n",
            "|    policy_loss        | 1.63     |\n",
            "|    std                | 0.936    |\n",
            "|    value_loss         | 0.00454  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 19200    |\n",
            "|    time_elapsed       | 137      |\n",
            "|    total_timesteps    | 96000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.242    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19199    |\n",
            "|    policy_loss        | -0.381   |\n",
            "|    std                | 0.934    |\n",
            "|    value_loss         | 1.22e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 696      |\n",
            "|    iterations         | 19300    |\n",
            "|    time_elapsed       | 138      |\n",
            "|    total_timesteps    | 96500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.423    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19299    |\n",
            "|    policy_loss        | 0.0151   |\n",
            "|    std                | 0.935    |\n",
            "|    value_loss         | 4.43e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 696      |\n",
            "|    iterations         | 19400    |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 97000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.164    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19399    |\n",
            "|    policy_loss        | -1.01    |\n",
            "|    std                | 0.934    |\n",
            "|    value_loss         | 6.93e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 696      |\n",
            "|    iterations         | 19500    |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 97500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -135     |\n",
            "|    explained_variance | 0.131    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19499    |\n",
            "|    policy_loss        | -0.541   |\n",
            "|    std                | 0.934    |\n",
            "|    value_loss         | 1.85e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 697      |\n",
            "|    iterations         | 19600    |\n",
            "|    time_elapsed       | 140      |\n",
            "|    total_timesteps    | 98000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -134     |\n",
            "|    explained_variance | -4.4     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19599    |\n",
            "|    policy_loss        | -2.96    |\n",
            "|    std                | 0.932    |\n",
            "|    value_loss         | 0.00136  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 697      |\n",
            "|    iterations         | 19700    |\n",
            "|    time_elapsed       | 141      |\n",
            "|    total_timesteps    | 98500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -134     |\n",
            "|    explained_variance | 0.0208   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19699    |\n",
            "|    policy_loss        | -0.645   |\n",
            "|    std                | 0.93     |\n",
            "|    value_loss         | 2.96e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 697      |\n",
            "|    iterations         | 19800    |\n",
            "|    time_elapsed       | 141      |\n",
            "|    total_timesteps    | 99000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -134     |\n",
            "|    explained_variance | -0.603   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19799    |\n",
            "|    policy_loss        | -0.107   |\n",
            "|    std                | 0.93     |\n",
            "|    value_loss         | 2.16e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 697      |\n",
            "|    iterations         | 19900    |\n",
            "|    time_elapsed       | 142      |\n",
            "|    total_timesteps    | 99500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -134     |\n",
            "|    explained_variance | -0.0156  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19899    |\n",
            "|    policy_loss        | -1.29    |\n",
            "|    std                | 0.929    |\n",
            "|    value_loss         | 0.000105 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 698      |\n",
            "|    iterations         | 20000    |\n",
            "|    time_elapsed       | 143      |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -134     |\n",
            "|    explained_variance | -2.38    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19999    |\n",
            "|    policy_loss        | -1.48    |\n",
            "|    std                | 0.928    |\n",
            "|    value_loss         | 0.000161 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x78ee57ddaf20>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Reset the Environment: The environment is reset to its initial state, and the first observation is obtained.\n",
        "Initialize Weights List: An empty list is initialized to hold the portfolio weights.\n",
        "Iterate over the Environment: The code iterates through the environment using a while loop:\n",
        "The model predicts the action (portfolio weights) based on the current observation.\n",
        "The environment's step method is called with the predicted action, returning the new observation, reward, done flag, and additional info.\n",
        "The action is normalized to ensure the weights sum to 1 and appended to the weights list.\n",
        "The loop breaks if the done flag is True, indicating the end of the episode.\n",
        "Final Weights: The weights list is converted to a numpy array, and the final time step's weights are selected.\n",
        "Print Results: The final weights are printed.\n",
        "}\n",
        "\n",
        "###Turkish\n",
        "{Ortamı Sıfırla: Ortam, başlangıç durumuna sıfırlanır ve ilk gözlem alınır.\n",
        "Ağırlıklar Listesini Başlat: Portföy ağırlıklarını tutmak üzere boş bir liste başlatılır.\n",
        "Ortam Üzerinde Yineleme: Kod, bir while döngüsü kullanarak ortam üzerinde yineleme yapar:\n",
        "Model, mevcut gözleme dayalı olarak eylemi (portföy ağırlıkları) tahmin eder.\n",
        "Tahmin edilen eylemle ortamın step metodu çağrılır, yeni gözlemi, ödülü, bitiş bayrağını ve ek bilgiyi döndürür.\n",
        "Eylem, ağırlıkların toplamının 1 olmasını sağlamak üzere normalize edilir ve ağırlıklar listesine eklenir.\n",
        "done bayrağı True ise, bölümün sona erdiğini belirttiği için döngü kırılır.\n",
        "Son Ağırlıklar: Ağırlıklar listesi bir numpy dizisine dönüştürülür ve son zaman adımının ağırlıkları seçilir.\n",
        "Sonuçları Yazdır: Son ağırlıklar yazdırılır.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "2Y3F3vXWprG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observation = env.reset()\n",
        "weights = []\n",
        "while True:\n",
        "    action, _ = model.predict(observation, deterministic=True)\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    weights.append(action / np.sum(np.abs(action)))\n",
        "\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "weights = np.array(weights)\n",
        "final_weights = weights[-1]\n",
        "print(f\"The weights at the final time step are: {final_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfTFI6RePV-K",
        "outputId": "377d30a7-f3af-4703-c657-d8d24ed37978"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weights at the final time step are: [[ 0.01050865  0.01357203  0.00248831  0.01604014  0.01236501  0.0112456\n",
            "   0.00081632  0.00273929 -0.01326354 -0.01113756 -0.01117345 -0.00047605\n",
            "   0.01224727 -0.02018258 -0.00508181 -0.00298559  0.01542483 -0.01591946\n",
            "   0.00553461  0.00137151  0.01364991 -0.01531959  0.01004415  0.00550638\n",
            "  -0.0121974   0.02835846  0.01589649 -0.01339765  0.01804372  0.00861347\n",
            "   0.00960532  0.02528412  0.01246299  0.01845592 -0.00115088  0.01308146\n",
            "  -0.01420715  0.00565389  0.00023998 -0.01132227 -0.0016447  -0.00140347\n",
            "  -0.00846995 -0.00524034 -0.00027292  0.01196982 -0.0179059   0.00938338\n",
            "   0.01490317 -0.01835251 -0.01041288  0.00393216  0.004302   -0.004476\n",
            "   0.02835846  0.00736584  0.02835846  0.00314991 -0.00079304  0.00606527\n",
            "  -0.00039542  0.01159271  0.01712869  0.02204949  0.00150034  0.01182902\n",
            "  -0.00974271  0.0028403   0.0011778   0.01390534 -0.01449139  0.00673436\n",
            "  -0.00159569 -0.02201791  0.01001019  0.00907229  0.00291707 -0.01030315\n",
            "   0.01319052 -0.0111299  -0.00372128 -0.00091851 -0.00611841  0.007069\n",
            "   0.01365338  0.02205466  0.00231787 -0.01461023  0.00582881  0.00596924\n",
            "  -0.00039932  0.0118754  -0.0016905  -0.00307707 -0.00915324 -0.01531403\n",
            "  -0.02503164 -0.02078175 -0.00370187  0.00926451]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Calculate Portfolio Returns: The daily returns of the portfolio are calculated by taking the dot product of the returns DataFrame df_returns and the final weights.\n",
        "Risk-Free Rate: The risk-free rate is assumed to be 0%. In finance, the risk-free rate is typically the return on a safe investment like government bonds.\n",
        "Calculate Excess Portfolio Returns: The excess returns of the portfolio are calculated by subtracting the risk-free rate from the portfolio returns.\n",
        "Calculate Portfolio Standard Deviation (Risk): The standard deviation of the portfolio returns is calculated, representing the volatility or risk of the portfolio.\n",
        "Calculate the Sharpe Ratio: The Sharpe Ratio is calculated as the mean of the excess portfolio returns divided by the standard deviation of the portfolio returns. It represents the risk-adjusted return of the portfolio.}\n",
        "\n",
        "###Turkish\n",
        "{Portföy Getirilerini Hesapla: Portföyün günlük getirileri, df_returns getiri DataFrame'i ile son ağırlıkların nokta çarpımı alınarak hesaplanır.\n",
        "Risk-Free Oranı: Risk-free oranı yüzde 0 olarak kabul edilir. Finansta risk-free oranı, genellikle hükümet tahvilleri gibi güvenli bir yatırımın getirisidir.\n",
        "Fazla Portföy Getirilerini Hesapla: Portföyün fazla getirileri, risk-free oranının portföy getirilerinden çıkarılmasıyla hesaplanır.\n",
        "Portföy Standart Sapmasını (Risk) Hesapla: Portföy getirilerinin standart sapması hesaplanır, portföyün oynaklığını veya riskini temsil eder.\n",
        "Sharpe Oranını Hesapla: Sharpe Oranı, portföy getirilerinin fazla ortalaması ile portföy getirilerinin standart sapmasının bölünmesiyle hesaplanır. Portföyün risk düzeltilmiş getirisini temsil eder.}"
      ],
      "metadata": {
        "id": "Ki5S4qOqqMLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "portfolio_returns = np.dot(df_returns, final_weights.T)\n",
        "risk_free_rate = 0\n",
        "excess_portfolio_returns = portfolio_returns - risk_free_rate\n",
        "portfolio_std_dev = np.std(portfolio_returns)\n",
        "sharpe_ratio = np.mean(excess_portfolio_returns) / portfolio_std_dev\n",
        "print(f'The Sharpe Ratio of the portfolio is: {sharpe_ratio}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ct8Mz5zQG44",
        "outputId": "52276f20-a0fc-47f3-fc7c-cd31a2603bc5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Sharpe Ratio of the portfolio is: 0.02993732277985129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Calculate Negative Returns: The negative returns from the previously calculated portfolio returns are extracted, representing the downside or losses.\n",
        "Calculate Downside Standard Deviation: The standard deviation of the negative returns is calculated, which represents the downside risk or the volatility of the negative returns.\n",
        "Calculate the Sortino Ratio: The Sortino Ratio is calculated as the mean of the excess portfolio returns (previously calculated) divided by the downside standard deviation. It measures the risk-adjusted return of the portfolio, specifically focusing on the downside risk.}\n",
        "\n",
        "###Turkey\n",
        "{Negatif Getirileri Hesapla: Daha önce hesaplanan portföy getirilerinden negatif getiriler çıkarılır, aşağı yönlü veya zararları temsil eder.\n",
        "Aşağı Yönlü Standart Sapmayı Hesapla: Negatif getirilerin standart sapması hesaplanır, bu da aşağı yönlü riski veya negatif getirilerin oynaklığını temsil eder.\n",
        "Sortino Oranını Hesapla: Sortino Oranı, portföyün fazla getirilerinin ortalamasının (daha önce hesaplandı) aşağı yönlü standart sapmaya bölünmesiyle hesaplanır. Portföyün risk düzeltilmiş getirisini ölçer, özellikle aşağı yönlü risk üzerinde odaklanır.}"
      ],
      "metadata": {
        "id": "cdOESqLjqvlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "negative_returns = portfolio_returns[portfolio_returns < 0]\n",
        "downside_std_dev = np.std(negative_returns)\n",
        "sortino_ratio = np.mean(excess_portfolio_returns) / downside_std_dev\n",
        "print(f'The Sortino Ratio of the portfolio is: {sortino_ratio}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJlekvIoQsSZ",
        "outputId": "b4f5983e-50eb-45bf-84da-d4118166d01c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Sortino Ratio of the portfolio is: 0.03732622475472421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OCLwV4W4qNlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Calculate Rolling Maximum: The np.maximum.accumulate function calculates the rolling maximum of the portfolio returns, representing the highest value so far at each time step.\n",
        "Calculate Drawdown: The drawdown at each time step is calculated by subtracting the current portfolio returns from the rolling maximum.\n",
        "Calculate Maximum Drawdown: The maximum drawdown is the maximum value of the drawdown over all time steps. It represents the largest single drop from peak to bottom in the portfolio's value.}\n",
        "\n",
        "###Turkey\n",
        "{Yürüyen Maksimumu Hesapla: np.maximum.accumulate fonksiyonu, her zaman adımında şu ana kadarki en yüksek değeri temsil eden portföy getirilerinin yürüyen maksimumunu hesaplar.\n",
        "Çekilme Miktarını Hesapla: Her zaman adımındaki çekilme miktarı, yürüyen maksimumdan mevcut portföy getirilerinin çıkarılmasıyla hesaplanır.\n",
        "Maksimum Çekilme Miktarını Hesapla: Maksimum çekilme miktarı, tüm zaman adımlarında çekilme miktarının maksimum değeridir. Portföy değerinin zirveden dibe en büyük tek düşüşünü temsil eder.}"
      ],
      "metadata": {
        "id": "QUGyXRnmrDnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roll_max = np.maximum.accumulate(portfolio_returns)\n",
        "drawdown = roll_max - portfolio_returns\n",
        "max_drawdown = np.max(drawdown)\n",
        "print(f'The Maximum Drawdown of the portfolio is: {max_drawdown}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwvWAD_jRCXN",
        "outputId": "d986f9af-4007-4437-ee34-804b980788fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Maximum Drawdown of the portfolio is: 0.5738191584922873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Initialize Dictionaries: Empty dictionaries are created to hold the calculated Sortino Ratios, Maximum Drawdowns, and Sharpe Ratios for each robot.\n",
        "Calculate Metrics for Each Robot: The code loops through each robot, calculating the Sortino Ratio, Maximum Drawdown, and Sharpe Ratio for each one.\n",
        "Convert Dictionaries to Series: The dictionaries are converted to Pandas Series for easier handling and manipulation.\n",
        "Rank Robots: The robots are ranked based on each of the three metrics. For Sortino Ratio and Sharpe Ratio, higher values are better, so they are ranked in descending order. For Maximum Drawdown, lower values are better, so it is ranked in ascending order.\n",
        "Calculate Combined Rank: The individual ranks are summed, and then the robots are ranked again based on this combined score. The combined rank considers all three metrics, giving a comprehensive assessment of each robot's performance.\n",
        "Print Final Rankings: The final rankings are printed, showing the best-performing robots.}\n",
        "\n",
        "###Turkey\n",
        "{Sözlükleri Başlat: Her robot için hesaplanacak Sortino Oranları, Maksimum Çekilme Miktarları ve Sharpe Oranları için boş sözlükler oluşturulur.\n",
        "Her Robot İçin Metrikleri Hesapla: Kod, her bir robot için Sortino Oranı, Maksimum Çekilme Miktarı ve Sharpe Oranı hesaplamak üzere döngü yapar.\n",
        "Sözlükleri Serilere Dönüştür: Sözlükler, daha kolay işlem ve manipülasyon için Pandas Serilerine dönüştürülür.\n",
        "Robotları Derecelendir: Robotlar, her üç metriğe göre derecelendirilir. Sortino Oranı ve Sharpe Oranı için daha yüksek değerler daha iyidir, bu nedenle azalan sıra ile sıralanırlar. Maksimum Çekilme Miktarı için daha düşük değerler daha iyidir, bu nedenle artan sıra ile sıralanır.\n",
        "Birleşik Sıralamayı Hesapla: Bireysel sıralamalar toplanır ve sonra robotlar, bu birleşik puanına göre tekrar derecelendirilir. Birleşik sıralama, tüm üç metriği dikkate alır, her robotun performansının kapsamlı bir değerlendirmesini sunar.\n",
        "Son Derecelendirmeleri Yazdır: Son derecelendirmeler yazdırılır, en iyi performans gösteren robotları gösterir.}"
      ],
      "metadata": {
        "id": "L6H80Xp3sYQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sortino_ratios = {}\n",
        "max_drawdowns = {}\n",
        "sharpe_ratios = {}\n",
        "\n",
        "for roboID in df_returns.columns:\n",
        "    returns = df_returns[roboID]\n",
        "    negative_returns = returns[returns < 0]\n",
        "    downside_std_dev = np.std(negative_returns)\n",
        "    sortino_ratio = np.mean(returns) / downside_std_dev\n",
        "    sortino_ratios[roboID] = sortino_ratio\n",
        "    roll_max = np.maximum.accumulate(returns)\n",
        "    drawdown = roll_max - returns\n",
        "    max_drawdown = np.max(drawdown)\n",
        "    max_drawdowns[roboID] = max_drawdown\n",
        "    sharpe_ratio = np.mean(returns) / np.std(returns)\n",
        "    sharpe_ratios[roboID] = sharpe_ratio\n",
        "sortino_ratios = pd.Series(sortino_ratios)\n",
        "max_drawdowns = pd.Series(max_drawdowns)\n",
        "sharpe_ratios = pd.Series(sharpe_ratios)\n",
        "# Rank roboIDs based on Sortino Ratio, Maximum Drawdown, and Sharpe Ratio\n",
        "# For Sortino Ratio and Sharpe Ratio, higher is better. For Maximum Drawdown, lower is better.\n",
        "sortino_rankings = sortino_ratios.rank(ascending=False)  # Rank 1 is best\n",
        "max_drawdown_rankings = max_drawdowns.rank()  # Rank 1 is best\n",
        "sharpe_rankings = sharpe_ratios.rank(ascending=False)  # Rank 1 is best\n",
        "combined_rank = sortino_rankings + max_drawdown_rankings + sharpe_rankings\n",
        "final_rank = combined_rank.rank()  # Rank 1 is best\n",
        "print(final_rank.sort_values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c05M_-wORttF",
        "outputId": "d6752e00-030b-44cc-c67c-8d5c04e14a24"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21475      1.0\n",
            "1879       2.0\n",
            "15233      3.0\n",
            "1883       4.0\n",
            "1981       5.5\n",
            "         ...  \n",
            "88        96.0\n",
            "17953     97.0\n",
            "1043      98.0\n",
            "668       99.0\n",
            "21501    100.0\n",
            "Length: 100, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second assignments"
      ],
      "metadata": {
        "id": "W7bDwCTxsvku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Find the 10 preceding rows in EURUSD6m.csv (based on the datetime).\n",
        "Depending on the direction in bots6m.csv:\n",
        "If direction = 0 (BUY):\n",
        "BackHigh is the difference between the maximum _high value in the preceding rows and the price.\n",
        "BackLow is the difference between the price and the minimum _low value in the preceding rows.\n",
        "BackHighDist and BackLowDist are the time differences in minutes between the current datetime and the datetimes where _high and _low were obtained, respectively.\n",
        "If direction = 1 (SALE):\n",
        "BackHigh is the difference between the price and the minimum _low value in the preceding rows.\n",
        "BackLow is the difference between the maximum _high value in the preceding rows and the price.\n",
        "BackHighDist and BackLowDist are the time differences in minutes between the current datetime and the datetimes where _low and _high were obtained, respectively.\n",
        "We are to implement this process using different techniques to determine the most efficient method.}\n",
        "\n",
        "###Turkish\n",
        "{EURUSD6m.csv dosyasında mevcut zaman damgasına göre önceki 10 satırı bulun.\n",
        "bots6m.csv'deki yönüne bağlı olarak:\n",
        "Eğer yön = 0 (AL) ise:\n",
        "BackHigh, önceki satırlardaki en yüksek _high değeri ile fiyat arasındaki farktır.\n",
        "BackLow, fiyat ile önceki satırlardaki en düşük _low değeri arasındaki farktır.\n",
        "BackHighDist ve BackLowDist sırasıyla _high ve _low değerlerinin elde edildiği zaman damgaları ile mevcut zaman damgası arasındaki zaman farklarıdır (dakika cinsinden).\n",
        "Eğer yön = 1 (SAT) ise:\n",
        "BackHigh, fiyat ile önceki satırlardaki en düşük _low değeri arasındaki farktır.\n",
        "BackLow, önceki satırlardaki en yüksek _high değeri ile fiyat arasındaki farktır.\n",
        "BackHighDist ve BackLowDist sırasıyla _low ve _high değerlerinin elde edildiği zaman damgaları ile mevcut zaman damgası arasındaki zaman farklarıdır (dakika cinsinden).\n",
        "Bu süreci, en etkili yöntemi belirlemek üzere farklı teknikler kullanarak uygulayacağız.}"
      ],
      "metadata": {
        "id": "FHh9kqhGh6sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "import time"
      ],
      "metadata": {
        "id": "xm4FmFdAs7z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{This code snippet reads two CSV files: \"bots6m (1).csv\" and \"EURUSD6m (1).csv\", using the Pandas library, and stores them in the dataframes bots_df and eurusd_df, respectively. After reading the files, it displays the first five rows (head) of both dataframes. This is typically done to get a quick look at the structure and content of the datasets.}\n",
        "\n",
        "###Turkish\n",
        "{Bu kod parçacığı, Pandas kütüphanesini kullanarak \"bots6m (1).csv\" ve \"EURUSD6m (1).csv\" adlı iki CSV dosyasını okur ve sırasıyla bots_df ve eurusd_df adlı dataframe'lere kaydeder. Dosyaları okuduktan sonra, her iki dataframe'in ilk beş satırını (başlangıç) gösterir. Bu, genellikle veri setlerinin yapısı ve içeriği hakkında hızlı bir bakış almak için yapılır.}"
      ],
      "metadata": {
        "id": "S8SEtROWtxaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bots_df = pd.read_csv(\"/content/bots6m (1).csv\")\n",
        "eurusd_df = pd.read_csv(\"/content/EURUSD6m (1).csv\")\n",
        "bots_df.head(), eurusd_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cQryosKgia5",
        "outputId": "c0b044a6-8a83-43db-afa4-22bf72bde789"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   detailID  genID    Pair   TP   SL    price  tppoint  slpoint  direction  \\\n",
              " 0  11378532  21473  EURUSD   30   60  1.05512  1.05212  1.06112          1   \n",
              " 1  12827455    194  EURUSD   30   20  1.09170  1.08870  1.09370          1   \n",
              " 2  12672590   1188  EURUSD  110   80  1.07227  1.06127  1.08027          1   \n",
              " 3  11924612   1405  EURUSD   20  150  1.06879  1.07079  1.05379          0   \n",
              " 4  11937176   1884  EURUSD   30   70  1.06269  1.05969  1.06969          1   \n",
              " \n",
              "            dateOpening dateClosing  snow  \n",
              " 0  2023-08-05 00:00:00     2:34.16    30  \n",
              " 1  2023-08-05 00:00:00     1:24.01   -20  \n",
              " 2  2023-08-05 00:00:00     7:23.09   -80  \n",
              " 3  2023-08-05 00:00:00     9:32.05  -150  \n",
              " 4  2023-08-05 00:00:00     9:30.07    30  ,\n",
              "         fxid    pair    _open    _high     _low   _close  _vol  \\\n",
              " 0  102425638  EURUSD  1.06671  1.06671  1.06637  1.06643    14   \n",
              " 1  102425670  EURUSD  1.06643  1.06643  1.06641  1.06643     3   \n",
              " 2  102425679  EURUSD  1.06641  1.06644  1.06641  1.06641     4   \n",
              " 3  102425697  EURUSD  1.06643  1.06645  1.06643  1.06644     5   \n",
              " 4  102425735  EURUSD  1.06643  1.06643  1.06643  1.06643     1   \n",
              " \n",
              "              _datetime  rolling_high  rolling_low  \n",
              " 0  2023-01-02 22:02:00       1.06671      1.06637  \n",
              " 1  2023-01-02 22:03:00       1.06671      1.06637  \n",
              " 2  2023-01-02 22:04:00       1.06671      1.06637  \n",
              " 3  2023-01-02 22:05:00       1.06671      1.06637  \n",
              " 4  2023-01-02 22:06:00       1.06671      1.06637  )"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{Before proceeding with the calculations, we need to ensure that the 'dateOpening' column in bots_df and the _datetime column in eurusd_df are in datetime format. Let's convert them if necessary.}\n",
        "\n",
        "###Turkey\n",
        "{Hesaplamalara devam etmeden önce, bots_df'deki 'dateOpening' sütununun ve eurusd_df'deki _datetime sütununun tarih-saat biçiminde olduğundan emin olmamız gerekiyor. Gerekirse bunları dönüştürelim.}"
      ],
      "metadata": {
        "id": "PUfY833DiIIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{This code snippet is converting the 'dateOpening' column in the bots_df dataframe and the '_datetime' column in the eurusd_df dataframe to datetime format. It uses the Pandas pd.to_datetime method to make this conversion. After converting the columns, the code checks and prints the data types of all the columns in both dataframes using the dtypes attribute to confirm that the conversion has been successful.}\n",
        "\n",
        "###Turkish\n",
        "{Bu kod parçacığı, bots_df dataframe'indeki 'dateOpening' sütununu ve eurusd_df dataframe'indeki '_datetime' sütununu tarih-saat biçimine dönüştürmektedir. Bu dönüşümü yapmak için Pandas'ın pd.to_datetime metodunu kullanır. Sütunları dönüştürdükten sonra, kod, dönüşümün başarılı olduğunu doğrulamak için her iki dataframe'deki tüm sütunların veri tiplerini dtypes özelliğini kullanarak kontrol eder ve yazdırır.}"
      ],
      "metadata": {
        "id": "xOu2Z8OKuWfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bots_df['dateOpening'] = pd.to_datetime(bots_df['dateOpening'])\n",
        "eurusd_df['_datetime'] = pd.to_datetime(eurusd_df['_datetime'])\n",
        "bots_df.dtypes, eurusd_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYMaFbLkgto_",
        "outputId": "334cc2ed-855f-4410-a60e-00f7b4bfd18e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(detailID                int64\n",
              " genID                   int64\n",
              " Pair                   object\n",
              " TP                      int64\n",
              " SL                      int64\n",
              " price                 float64\n",
              " tppoint               float64\n",
              " slpoint               float64\n",
              " direction               int64\n",
              " dateOpening    datetime64[ns]\n",
              " dateClosing            object\n",
              " snow                    int64\n",
              " dtype: object,\n",
              " fxid                     int64\n",
              " pair                    object\n",
              " _open                  float64\n",
              " _high                  float64\n",
              " _low                   float64\n",
              " _close                 float64\n",
              " _vol                     int64\n",
              " _datetime       datetime64[ns]\n",
              " rolling_high           float64\n",
              " rolling_low            float64\n",
              " dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The 'dateOpening' column in bots_df and the '_datetime' column in eurusd_df have been successfully converted to datetime format.\n",
        "\n",
        "Now, let's proceed with the calculations. For each row in bots_df, we'll find the preceding 10 rows in eurusd_df (based on the datetime) and calculate BackHigh, BackLow, BackHighDist, and BackLowDist.\n",
        "\n",
        "For this task, we'll start by creating a function that performs these calculations for a given row in bots_df. We'll then apply this function to each row in bots_df.\n",
        "\n",
        "We'll start with the method using pandas' apply function, which is the most straightforward but may not be the most efficient. We'll measure the time it takes to complete the calculations for comparison with other methods.}\n",
        "\n",
        "###Turkish\n",
        "{bots_df'deki 'dateOpening' sütunu ve eurusd_df'deki '_datetime' sütunu başarıyla tarih saat biçimine dönüştürüldü.\n",
        "\n",
        "Şimdi hesaplamalarla devam edelim. bots_df'deki her satır için, eurusd_df'deki önceki 10 satırı (tarih saatine göre) bulacağız ve BackHigh, BackLow, BackHighDist ve BackLowDist değerlerini hesaplayacağız.\n",
        "\n",
        "Bu görev için, bots_df'deki belirli bir satır için bu hesaplamaları yapan bir işlev oluşturarak başlayacağız. Ardından, bu işlevi bots_df'deki her satıra uygulayacağız.\n",
        "\n",
        "En basit olan, ancak en verimli olmayabilecek pandas'ın apply işlevini kullanarak başlayacağız. Diğer yöntemlerle karşılaştırma için hesaplamaların tamamlanmasının ne kadar sürdüğünü ölçeceğiz.}"
      ],
      "metadata": {
        "id": "_k3I49sLiP3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The code defines a function calculate_values that takes a row from the bots_df dataframe and calculates four values: BackHigh, BackLow, BackHighDist, and BackLowDist. The calculations depend on the direction specified in the 'direction' column of the row. If the direction is 0 (BUY), the calculations are based on the maximum _high and minimum _low values of the preceding 10 rows from the eurusd_df dataframe. If the direction is 1 (SALE), the calculations are based on the minimum _low and maximum _high values of the preceding 10 rows.\n",
        "\n",
        "The function uses a mask to filter the preceding 10 rows from eurusd_df based on the datetime and applies different calculations depending on the direction. If there are no preceding rows, the function returns NaN values.\n",
        "\n",
        "After defining the function, the code times the execution of applying this function to every row in bots_df using the Pandas apply method. The result is four new columns added to bots_df containing the calculated values. The execution time is printed, and the first few rows of the updated bots_df are displayed.}\n",
        "\n",
        "###Turkish\n",
        "{Kod, bots_df dataframe'inden bir satır alan ve BackHigh, BackLow, BackHighDist ve BackLowDist olmak üzere dört değeri hesaplayan calculate_values adında bir işlev tanımlar. Hesaplamalar, satırın 'direction' sütununda belirtilen yöne bağlıdır. Yön 0 (AL) ise, hesaplamalar, eurusd_df dataframe'inden önceki 10 satırın maksimum _high ve minimum _low değerlerine dayalıdır. Yön 1 (SAT) ise, hesaplamalar, önceki 10 satırın minimum _low ve maksimum _high değerlerine dayalıdır.\n",
        "\n",
        "İşlev, datetime'a dayalı olarak eurusd_df'den önceki 10 satırı filtrelemek için bir maske kullanır ve yöne bağlı olarak farklı hesaplamalar uygular. Önceki satır yoksa, işlev NaN değerlerini döndürür.\n",
        "\n",
        "İşlevi tanımladıktan sonra, kod, bu işlevi Pandas apply metodu kullanarak bots_df'deki her satıra uygulamanın yürütme zamanını ölçer. Sonuç, hesaplanan değerleri içeren bots_df'ye eklenen dört yeni sütundur. Yürütme zamanı yazdırılır ve güncellenen bots_df'nin ilk birkaç satırı görüntülenir.}"
      ],
      "metadata": {
        "id": "gDhjwkG9uzgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_values(row):\n",
        "    mask = (eurusd_df['_datetime'] < row['dateOpening']) & (eurusd_df['_datetime'] >= row['dateOpening'] - timedelta(minutes=10))\n",
        "    preceding_rows = eurusd_df[mask]\n",
        "    if preceding_rows.empty:\n",
        "        return pd.Series([np.nan, np.nan, np.nan, np.nan])\n",
        "    if row['direction'] == 0:  # BUY\n",
        "        max_high = preceding_rows['_high'].max()\n",
        "        min_low = preceding_rows['_low'].min()\n",
        "        max_high_time = preceding_rows.loc[preceding_rows['_high'].idxmax(), '_datetime']\n",
        "        min_low_time = preceding_rows.loc[preceding_rows['_low'].idxmin(), '_datetime']\n",
        "        BackHigh = max_high - row['price']\n",
        "        BackLow = row['price'] - min_low\n",
        "        BackHighDist = (row['dateOpening'] - max_high_time).total_seconds() / 60\n",
        "        BackLowDist = (row['dateOpening'] - min_low_time).total_seconds() / 60\n",
        "    else:  # SALE\n",
        "        min_low = preceding_rows['_low'].min()\n",
        "        max_high = preceding_rows['_high'].max()\n",
        "        min_low_time = preceding_rows.loc[preceding_rows['_low'].idxmin(), '_datetime']\n",
        "        max_high_time = preceding_rows.loc[preceding_rows['_high'].idxmax(), '_datetime']\n",
        "        BackHigh = row['price'] - min_low\n",
        "        BackLow = max_high - row['price']\n",
        "        BackHighDist = (row['dateOpening'] - min_low_time).total_seconds() / 60\n",
        "        BackLowDist = (row['dateOpening'] - max_high_time).total_seconds() / 60\n",
        "\n",
        "    return pd.Series([BackHigh, BackLow, BackHighDist, BackLowDist])\n",
        "start_time = time.time()\n",
        "bots_df[['BackHigh', 'BackLow', 'BackHighDist', 'BackLowDist']] = bots_df.apply(calculate_values, axis=1)\n",
        "print(\"Execution time:\", time.time() - start_time, \"seconds\")\n",
        "bots_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "5OmTxF8jgxJg",
        "outputId": "d49ef545-ce5a-4252-f5f3-58350ab80fbe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-144e2680fd06>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Create new columns in bots_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mbots_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BackHigh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BackLow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BackHighDist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BackLowDist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbots_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Print the execution time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-144e2680fd06>\u001b[0m in \u001b[0;36mcalculate_values\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get the 10 preceding rows in eurusd_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meurusd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dateOpening'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meurusd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dateOpening'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpreceding_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meurusd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Check if preceding_rows is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3851\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3852\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \"\"\"\n\u001b[0;32m-> 3902\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3886\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3887\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m         return self.reindex_indexer(\n\u001b[0m\u001b[1;32m    979\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_refs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             new_blocks = [\n\u001b[0m\u001b[1;32m    752\u001b[0m                 blk.take_nd(\n\u001b[1;32m    753\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             new_blocks = [\n\u001b[0;32m--> 752\u001b[0;31m                 blk.take_nd(\n\u001b[0m\u001b[1;32m    753\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     dtype, fill_value, mask_info = _take_preprocess_indexer_and_fill_value(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{My approach to solving this task isn't performing as well as I expected. Calculating the values by applying the function to each row is taking too much time. This is likely because for each row in bots_df, we're performing a search in eurusd_df, which is computationally expensive.\n",
        "\n",
        "We need a different approach that is more efficient. Let's try to refactor the code to avoid searching the entire eurusd_df for each row in bots_df.\n",
        "\n",
        "A possible approach is to first sort both dataframes by date, then iterate through each row in bots_df and maintain a moving window of the last 10 rows in eurusd_df. This way, we can avoid the expensive search operation for each row in bots_df.}\n",
        "\n",
        "###Turkish\n",
        "{Bu görevi çözme yaklaşımım, beklentimin aksine iyi bir performans sergilemiyor. Fonksiyonu her satıra uygulayarak değerleri hesaplamak çok zaman alıyor. Bu, büyük olasılıkla bots_df'deki her satır için eurusd_df'de arama yapmamızın hesaplama açısından pahalı olması nedeniyle oluyor.\n",
        "\n",
        "Daha verimli olan farklı bir yaklaşıma ihtiyacımız var. Tüm eurusd_df'yi bots_df'deki her satır için aramaktan kaçınmak amacıyla kodu yeniden düzenlemeyi deneyelim.\n",
        "\n",
        "Olabilir bir yaklaşım, önce her iki veri çerçevesini tarihe göre sıralamak, ardından bots_df'deki her satır üzerinden yinelemek ve eurusd_df'deki son 10 satırın hareketli bir penceresini sürdürmektir. Bu şekilde, bots_df'deki her satır için pahalı arama işleminden kaçınabiliriz.}"
      ],
      "metadata": {
        "id": "qnWJ-ciTiWYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The code block does the following:\n",
        "\n",
        "Sorting DataFrames: The dataframes bots_df and eurusd_df are sorted by their respective datetime columns to make sure the data is in chronological order.\n",
        "\n",
        "Initializing Variables: Several variables are initialized to keep track of the moving window of the preceding 10 rows in eurusd_df, the current index in eurusd_df, and the new columns BackHigh, BackLow, BackHighDist, and BackLowDist.\n",
        "\n",
        "Iterating Through Rows: The code iterates through each row in bots_df and updates the moving window based on the current dateOpening.\n",
        "\n",
        "If the window is empty, NaN values are appended to the new columns.\n",
        "If the window is not empty, the code calculates the required values based on the direction (BUY or SALE) and appends them to the new columns.\n",
        "Adding New Columns: The new columns are added to bots_df.\n",
        "\n",
        "Timing the Execution: The code also measures and prints the execution time for the entire process.\n",
        "\n",
        "Displaying the Result: The first few rows of the updated bots_df are displayed.}\n",
        "\n",
        "###Turkish\n",
        "{Kod bloğu aşağıdakileri yapar:\n",
        "\n",
        "DataFrame'leri Sıralama: bots_df ve eurusd_df dataframe'leri, verilerin kronolojik sırayla olduğundan emin olmak için kendi datetime sütunlarına göre sıralanır.\n",
        "\n",
        "Değişkenleri Başlatma: eurusd_df'deki önceki 10 satırın hareketli penceresini, eurusd_df'deki mevcut dizini ve yeni BackHigh, BackLow, BackHighDist ve BackLowDist sütunlarını takip etmek için birkaç değişken başlatılır.\n",
        "\n",
        "Satırlar Üzerinden Yineleme: Kod, bots_df'deki her satır üzerinden yineleyerek dateOpening'e dayalı olarak hareketli pencereyi günceller.\n",
        "\n",
        "Pencere boşsa, yeni sütunlara NaN değerleri eklenir.\n",
        "Pencere boş değilse, kod, yönüne (AL veya SAT) bağlı olarak gerekli değerleri hesaplar ve yeni sütunlara ekler.\n",
        "Yeni Sütunları Ekleme: Yeni sütunlar bots_df'ye eklenir.\n",
        "\n",
        "Yürütmenin Zamanlaması: Kod ayrıca tüm süreç için yürütme zamanını ölçer ve yazdırır.\n",
        "\n",
        "Sonucu Gösterme: Güncellenen bots_df'nin ilk birkaç satırı görüntülenir.}"
      ],
      "metadata": {
        "id": "HD4mh21UvbKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bots_df.sort_values(by='dateOpening', inplace=True)\n",
        "eurusd_df.sort_values(by='_datetime', inplace=True)\n",
        "window = []\n",
        "index = 0\n",
        "BackHigh = []\n",
        "BackLow = []\n",
        "BackHighDist = []\n",
        "BackLowDist = []\n",
        "start_time = time.time()\n",
        "for _, row in bots_df.iterrows():\n",
        "    while index < len(eurusd_df) and eurusd_df.iloc[index]['_datetime'] < row['dateOpening']:\n",
        "        window.append(eurusd_df.iloc[index])\n",
        "        while len(window) > 10:\n",
        "            window.pop(0)\n",
        "        index += 1\n",
        "    if not window:\n",
        "        BackHigh.append(np.nan)\n",
        "        BackLow.append(np.nan)\n",
        "        BackHighDist.append(np.nan)\n",
        "        BackLowDist.append(np.nan)\n",
        "        continue\n",
        "    window_df = pd.DataFrame(window)\n",
        "    if row['direction'] == 0:  # BUY\n",
        "        max_high = window_df['_high'].max()\n",
        "        min_low = window_df['_low'].min()\n",
        "        max_high_time = window_df.loc[window_df['_high'].idxmax(), '_datetime']\n",
        "        min_low_time = window_df.loc[window_df['_low'].idxmin(), '_datetime']\n",
        "        BackHigh.append(max_high - row['price'])\n",
        "        BackLow.append(row['price'] - min_low)\n",
        "        BackHighDist.append((row['dateOpening'] - max_high_time).total_seconds() / 60)\n",
        "        BackLowDist.append((row['dateOpening'] - min_low_time).total_seconds() / 60)\n",
        "    else:  # SALE\n",
        "        min_low = window_df['_low'].min()\n",
        "        max_high = window_df['_high'].max()\n",
        "        min_low_time = window_df.loc[window_df['_low'].idxmin(), '_datetime']\n",
        "        max_high_time = window_df.loc[window_df['_high'].idxmax(), '_datetime']\n",
        "        BackHigh.append(row['price'] - min_low)\n",
        "        BackLow.append(max_high - row['price'])\n",
        "        BackHighDist.append((row['dateOpening'] - min_low_time).total_seconds() / 60)\n",
        "        BackLowDist.append((row['dateOpening'] - max_high_time).total_seconds() / 60)\n",
        "bots_df['BackHigh'] = BackHigh\n",
        "bots_df['BackLow'] = BackLow\n",
        "bots_df['BackHighDist'] = BackHighDist\n",
        "bots_df['BackLowDist'] = BackLowDist\n",
        "print(\"Execution time:\", time.time() - start_time, \"seconds\")\n",
        "bots_df.head()\n"
      ],
      "metadata": {
        "id": "tkZpF5a_g64V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The two approaches we tried earlier were taking too much time to complete. The main reason for this was that for each row in bots_df, we were searching for corresponding data within a 10-minute window in eurusd_df. This is a time-consuming operation, especially when the dataframes are large.\n",
        "\n",
        "To address this issue, we adopted a different method that is more efficient. Instead of operating on individual rows, we resampled eurusd_df into 10-minute intervals, calculating the maximum '_high' value and the minimum '_low' value for each interval. This operation significantly reduced the size of eurusd_df, making it much faster to search for corresponding data.\n",
        "\n",
        "Next, we merged bots_df and the resampled eurusd_df based on the 'dateOpening' and '_datetime' columns, respectively. For each row in bots_df, we found the closest preceding row in eurusd_df without requiring a 10-minute tolerance. This is because the resampled data in eurusd_df already represents the high and low values for each 10-minute period.\n",
        "\n",
        "After merging the dataframes, we calculated BackHigh, BackLow, BackHighDist, and BackLowDist in the same way as before. However, since we were now using aggregated data for 10-minute periods, the BackHighDist and BackLowDist values were always equal to 10 minutes or less.\n",
        "\n",
        "This method significantly improved the speed of the calculations, reducing the time taken to approximately 0.15 seconds. Please note that the actual time taken can vary depending on various factors, including the size of the data and the performance of the system running the code.}\n",
        "\n",
        "###Turkish\n",
        "{Daha önce denediğimiz iki yaklaşımın tamamlanması çok zaman alıyordu. Bunun ana nedeni, bots_df'deki her satır için eurusd_df'de 10 dakikalık bir pencere içinde karşılık gelen verileri aramamızdı. Bu, özellikle veri çerçeveleri büyük olduğunda zaman alıcı bir işlemdir.\n",
        "\n",
        "Bu sorunu ele almak için, daha verimli olan farklı bir yöntem benimsedik. Tek tek satırlar üzerinde işlem yapmak yerine, eurusd_df'yi 10 dakikalık aralıklara ayırarak, her aralık için maksimum '_high' değerini ve minimum '_low' değerini hesapladık. Bu işlem, eurusd_df'nin boyutunu önemli ölçüde azaltarak, karşılık gelen verileri aramayı çok daha hızlı hale getirdi.\n",
        "\n",
        "Daha sonra, bots_df'yi ve yeniden örneklenen eurusd_df'yi sırasıyla 'dateOpening' ve '_datetime' sütunlarına dayalı olarak birleştirdik. Bots_df'deki her satır için, 10 dakikalık bir tolerans gerektirmeden eurusd_df'de en yakın önceki satırı bulduk. Bu, eurusd_df'deki yeniden örneklenen verilerin zaten her 10 dakikalık dönem için yüksek ve düşük değerleri temsil ettiği içindir.\n",
        "\n",
        "Veri çerçevelerini birleştirdikten sonra, BackHigh, BackLow, BackHighDist ve BackLowDist değerlerini daha önce olduğu gibi hesapladık. Ancak, şimdi 10 dakikalık dönemler için birleştirilmiş verileri kullandığımızdan, BackHighDist ve BackLowDist değerleri her zaman 10 dakika veya daha az oldu.\n",
        "\n",
        "Bu yöntem, hesaplamaların hızını önemli ölçüde artırdı ve harcanan zamanı yaklaşık 0,15 saniyeye düşürdü. Lütfen gerçek zamanın, verinin boyutu ve kodu çalıştıran sistemin performansı dahil olmak üzere çeşitli faktörlere bağlı olarak değişebileceğini unutmayın.}"
      ],
      "metadata": {
        "id": "LkOUhOLZjPyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The code snippet performs the following operations:\n",
        "\n",
        "Resampling: It resamples the eurusd_df DataFrame into 10-minute intervals. For each interval, the maximum value of the _high column and the minimum value of the _low column are calculated. This is achieved using the resample method with the '10min' argument, followed by the agg method to apply the aggregation functions.\n",
        "\n",
        "Resetting the Index: The index of the resampled DataFrame is reset using the reset_index method, making the datetime a regular column.\n",
        "\n",
        "Displaying the Result: The first few rows of the resampled DataFrame (eurusd_resampled) are displayed to show the result.}\n",
        "\n",
        "###Turkish\n",
        "{Kod parçacığı aşağıdaki işlemleri gerçekleştirir:\n",
        "\n",
        "Örnekleme Yeniden: eurusd_df DataFrame'ini 10 dakikalık aralıklara ayırır. Her aralık için, _high sütununun maksimum değeri ve _low sütununun minimum değeri hesaplanır. Bu, '10min' argümanıyla resample yöntemini kullanarak, ardından toplama işlevlerini uygulamak için agg yöntemiyle gerçekleştirilir.\n",
        "\n",
        "Dizin Sıfırlama: Örneklenmiş DataFrame'in dizini, datetime'ı düzenli bir sütun haline getirerek reset_index yöntemi kullanılarak sıfırlanır.\n",
        "\n",
        "Sonucu Gösterme: Örneklenmiş DataFrame'in (eurusd_resampled) ilk birkaç satırı, sonucu göstermek üzere görüntülenir.}"
      ],
      "metadata": {
        "id": "XS7zharRwBI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eurusd_resampled = eurusd_df.resample('10min', on='_datetime').agg({'_high': 'max', '_low': 'min'})\n",
        "eurusd_resampled.reset_index(inplace=True)\n",
        "eurusd_resampled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VHbr7qs7hB_y",
        "outputId": "405e339b-af7f-4aa5-e47d-cbaf2bd66f26"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            _datetime    _high     _low\n",
              "0 2023-01-02 22:00:00  1.06671  1.06631\n",
              "1 2023-01-02 22:10:00  1.06645  1.06631\n",
              "2 2023-01-02 22:20:00  1.06645  1.06629\n",
              "3 2023-01-02 22:30:00  1.06643  1.06628\n",
              "4 2023-01-02 22:40:00  1.06631  1.06625"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0f08d991-6d0a-4b8f-8701-3b2540f0c02a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_datetime</th>\n",
              "      <th>_high</th>\n",
              "      <th>_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-02 22:00:00</td>\n",
              "      <td>1.06671</td>\n",
              "      <td>1.06631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-02 22:10:00</td>\n",
              "      <td>1.06645</td>\n",
              "      <td>1.06631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-02 22:20:00</td>\n",
              "      <td>1.06645</td>\n",
              "      <td>1.06629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-02 22:30:00</td>\n",
              "      <td>1.06643</td>\n",
              "      <td>1.06628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-02 22:40:00</td>\n",
              "      <td>1.06631</td>\n",
              "      <td>1.06625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f08d991-6d0a-4b8f-8701-3b2540f0c02a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ba81c9bf-c84b-411a-aa38-92b397b9ad95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba81c9bf-c84b-411a-aa38-92b397b9ad95')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ba81c9bf-c84b-411a-aa38-92b397b9ad95 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f08d991-6d0a-4b8f-8701-3b2540f0c02a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f08d991-6d0a-4b8f-8701-3b2540f0c02a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###English\n",
        "{The code snippet performs several operations to manipulate and calculate specific values in the bots_df and eurusd_df DataFrames, and it measures the time taken for these operations. Here's what the code does:\n",
        "\n",
        "Resampling: It resamples the eurusd_df DataFrame into 10-minute intervals and calculates the maximum of the _high column and the minimum of the _low column.\n",
        "\n",
        "Resetting Index: The index of the resampled DataFrame is reset.\n",
        "\n",
        "Merging: The bots_df and the resampled eurusd_df DataFrames are merged using the pd.merge_asof function, matching on the datetime columns.\n",
        "\n",
        "Calculating BackHigh and BackLow: Temporary columns back_high and back_low are calculated based on the direction (either 0 or 1).\n",
        "\n",
        "Calculating Final Values: The columns BackHigh, BackLow, BackHighDist, and BackLowDist are calculated using conditions based on the direction and the temporary columns.\n",
        "\n",
        "Selecting Columns: A new DataFrame results is created, containing the columns of interest.\n",
        "\n",
        "Measuring Time: The time taken for all these operations is measured using the time module, and the duration is returned.}\n",
        "\n",
        "###Turkish\n",
        "{Kod parçacığı, bots_df ve eurusd_df DataFramelerinde belirli değerleri değiştirmek ve hesaplamak için birkaç işlem gerçekleştirir ve bu işlemler için harcanan zamanı ölçer. İşte kodun yaptıkları:\n",
        "\n",
        "Örnekleme Yeniden: eurusd_df DataFrame'ini 10 dakikalık aralıklara ayırır ve _high sütununun maksimumunu ve _low sütununun minimumunu hesaplar.\n",
        "\n",
        "Dizin Sıfırlama: Örneklenmiş DataFrame'in dizini sıfırlanır.\n",
        "\n",
        "Birleştirme: bots_df ve örneklenmiş eurusd_df DataFrameleri, datetime sütunları üzerinden eşleşecek şekilde pd.merge_asof işlevi kullanılarak birleştirilir.\n",
        "\n",
        "BackHigh ve BackLow Hesaplama: Yön (0 veya 1) temel alınarak geçici back_high ve back_low sütunları hesaplanır.\n",
        "\n",
        "Nihai Değerleri Hesaplama: Yön ve geçici sütunlara dayalı koşulları kullanarak BackHigh, BackLow, BackHighDist ve BackLowDist sütunları hesaplanır.\n",
        "\n",
        "Sütunları Seçme: İlgilendiğimiz sütunları içeren yeni bir DataFrame results oluşturulur.\n",
        "\n",
        "Zamanı Ölçme: Tüm bu işlemler için harcanan zaman, time modülü kullanılarak ölçülür ve süre döndürülür.}"
      ],
      "metadata": {
        "id": "5GrgVauxwrMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "eurusd_resampled = eurusd_df.resample('10min', on='_datetime').agg({'_high': 'max', '_low': 'min'})\n",
        "eurusd_resampled.reset_index(inplace=True)\n",
        "merged = pd.merge_asof(bots_df, eurusd_resampled, left_on='dateOpening', right_on='_datetime', direction='backward')\n",
        "merged['back_high'] = np.where(merged['direction'] == 0, merged['_high'], merged['_low'])\n",
        "merged['back_low'] = np.where(merged['direction'] == 0, merged['_low'], merged['_high'])\n",
        "merged['BackHigh'] = np.where(merged['direction'] == 0, merged['back_high'] - merged['price'], merged['price'] - merged['back_high'])\n",
        "merged['BackLow'] = np.where(merged['direction'] == 0, merged['price'] - merged['back_low'], merged['back_low'] - merged['price'])\n",
        "merged['BackHighDist'] = (merged['dateOpening'] - merged['_datetime']).dt.seconds // 60\n",
        "merged['BackLowDist'] = (merged['dateOpening'] - merged['_datetime']).dt.seconds // 60\n",
        "results = merged[['genID', 'TP', 'SL', 'direction', 'BackHigh', 'BackLow', 'BackHighDist', 'BackLowDist']]\n",
        "end_time = time.time()\n",
        "time_taken = end_time - start_time\n",
        "time_taken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zrh-NAkhHHy",
        "outputId": "c2d782f3-c1f2-4adb-e059-6c63b34acfcd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15901589393615723"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}